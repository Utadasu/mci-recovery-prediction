#!/usr/bin/env python3
"""
ğŸ¯ MCIæ¢å¤é¢„æµ‹ç³»ç»Ÿ
==================

åŸºäºå·²è®­ç»ƒçš„å¯¹æŠ—æ€§å¯¹æ¯”å­¦ä¹ æ¨¡å‹è¿›è¡ŒMCIæ¢å¤é¢„æµ‹
- ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æå–å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾
- è®­ç»ƒä¸‹æ¸¸åˆ†ç±»å™¨é¢„æµ‹MCIæ‚£è€…æ˜¯å¦æ¢å¤ä¸ºè®¤çŸ¥æ­£å¸¸(CN)
- æ”¯æŒäº¤å‰éªŒè¯å’Œç‹¬ç«‹æµ‹è¯•
- è®¡ç®—è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡å’ŒROCæ›²çº¿
- æ”¯æŒæ¨¡å‹ä¿å­˜å’ŒåŠ è½½

ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-12-23
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import os
from collections import defaultdict
from sklearn.model_selection import KFold, train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, 
    confusion_matrix, roc_auc_score, roc_curve, classification_report
)
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import re
import time
from datetime import datetime
import random

# å¯¼å…¥å·²æœ‰çš„æ¨¡å‹
from adversarial_contrastive_learning import AdversarialContrastiveModel
from text_encoder_module import AdversarialTextEncoder

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œé¿å…ç¼–ç é—®é¢˜
plt.rcParams['font.size'] = 10
plt.rcParams['axes.unicode_minus'] = False  # ä¿®å¤è´Ÿå·æ˜¾ç¤º
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300

# å…¨å±€éšæœºç§å­ï¼Œç¡®ä¿å¯é‡å¤æ€§
RANDOM_SEED = 42

def set_seed(seed=RANDOM_SEED):
    """è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿æ‰€æœ‰åº“çš„ç»“æœå¯é‡å¤"""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)

    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"ğŸŒ± å…¨å±€éšæœºç§å­å·²è®¾ç½®ä¸º: {seed}")

# æ¨èé…ç½®
RECOMMENDED_CONFIG = {
    'fusion_strategy': 'image_only',  # ä½¿ç”¨å›¾åƒç‰¹å¾è¿›è¡Œåˆ†ç±»
    'classifier_type': 'xgb',  # ä½¿ç”¨XGBoostæ¨¡å‹
    'regularization_strength': 10.0,
    'cross_validation': 'kfold',  # ä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯
    'kfold_splits': 5,
    'feature_standardization': True,
    'max_iter': 6000,
    'feature_noise_std': 0.0,
    'expected_accuracy_range': (0.75, 0.90),
    'ensemble_voting': True,
    'use_region_ensemble': False,
    'probability_calibration': True,
    'temperature_scaling': True,
    'focal_loss_gamma': 2.0,
    'label_smoothing': 0.1,
    'adaptive_regularization': True,
    'data_augmentation': True,
    'max_acceptable_random_acc': 0.60,
    'min_accuracy_diff': 0.15,
}

class MCIDataLoader:
    """MCIæ•°æ®åŠ è½½å™¨ï¼Œç”¨äºåŠ è½½å’Œå¤„ç†MCIæ‚£è€…æ•°æ®"""
    
    def __init__(self, data_dir):
        self.data_dir = data_dir
        self.mci_recovered_dir = os.path.join(data_dir, 'totalMCI_Recovered')  # æ¢å¤ä¸ºCNçš„MCIæ‚£è€…
        self.mci_not_recovered_dir = os.path.join(data_dir, 'totalMCI_NotRecovered')  # æœªæ¢å¤çš„MCIæ‚£è€…
        self.metadata_file = os.path.join(data_dir, 'mci_recovery_metadata.xlsx')
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        self._check_paths()
        
        print(f"ğŸ”§ åˆå§‹åŒ–MCIæ•°æ®åŠ è½½å™¨...")
        print(f"   MCIæ¢å¤æ‚£è€…ç›®å½•: {self.mci_recovered_dir}")
        print(f"   MCIæœªæ¢å¤æ‚£è€…ç›®å½•: {self.mci_not_recovered_dir}")
        print(f"   å…ƒæ•°æ®æ–‡ä»¶: {self.metadata_file}")
    
    def _check_paths(self):
        """æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨"""
        if not os.path.exists(self.data_dir):
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
        
        # æ£€æŸ¥MCIæ¢å¤å’Œæœªæ¢å¤ç›®å½•
        for dir_path, dir_name in [(self.mci_recovered_dir, 'MCIæ¢å¤æ‚£è€…'), (self.mci_not_recovered_dir, 'MCIæœªæ¢å¤æ‚£è€…')]:
            if not os.path.exists(dir_path):
                # å°è¯•å…¶ä»–å¯èƒ½çš„ç›®å½•å
                alt_dirs = [
                    dir_path.replace('total', ''),
                    dir_path.replace('total', 'MCI'),
                    dir_path.replace('total', 'mci'),
                    dir_path.lower(),
                    dir_path.replace('MCI', 'mci')
                ]
                for alt_path in alt_dirs:
                    if os.path.exists(alt_path):
                        dir_path = alt_path
                        break
                else:
                    raise FileNotFoundError(f"{dir_name}ç›®å½•ä¸å­˜åœ¨: {dir_path}")
    
    def load_mci_images(self):
        """åŠ è½½MCIæ‚£è€…å›¾åƒæ•°æ®"""
        print(f"ğŸ”„ åŠ è½½MCIå›¾åƒæ•°æ®...")
        
        # ç”¨äºå­˜å‚¨å„æ¨¡æ€å›¾åƒçš„å­—å…¸
        id_to_modalities = defaultdict(dict)
        patient_labels = {}
        
        # åŠ è½½æ¢å¤å’Œæœªæ¢å¤çš„MCIæ‚£è€…å›¾åƒ
        for patient_group, label, folder_name in [
            ('Recovered', 1, self.mci_recovered_dir),
            ('NotRecovered', 0, self.mci_not_recovered_dir)
        ]:
            print(f"   æ‰«æ{patient_group}æ‚£è€…ç›®å½•: {folder_name}")
            for modality, folder_suffix in [('CSF', 'CSF'), ('GRAY', 'GRAY'), ('WHITE', 'WHITE')]:
                modality_dir = os.path.join(folder_name, f'total{modality}')
                if not os.path.exists(modality_dir):
                    print(f"âš ï¸ è­¦å‘Š: {patient_group} {modality}æ¨¡æ€ç›®å½•ä¸å­˜åœ¨: {modality_dir}")
                    continue
                    
                print(f"   æ‰«æ{patient_group} {modality}æ¨¡æ€: {modality_dir}")
                for file in os.listdir(modality_dir):
                    if file.endswith('.nii') or file.endswith('.nii.gz'):
                        file_path = os.path.join(modality_dir, file)
                        try:
                            # æå–æ‚£è€…ID
                            patient_id = self._extract_patient_id_from_filename(file)
                            if patient_id:
                                id_to_modalities[patient_id][modality] = file_path
                                patient_labels[patient_id] = label
                        except Exception as e:
                            print(f"âš ï¸ è­¦å‘Š: å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        
        # å¤„ç†æ”¶é›†åˆ°çš„å›¾åƒæ•°æ®
        images = []
        labels = []
        patient_ids = []
        
        # æ£€æŸ¥æ¯ä¸ªæ‚£è€…æ˜¯å¦æœ‰å®Œæ•´çš„ä¸‰æ¨¡æ€æ•°æ®
        for patient_id, modalities in id_to_modalities.items():
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‰ä¸ªæ¨¡æ€
            required_keys = ['CSF', 'GRAY', 'WHITE']
            if all(key in modalities for key in required_keys):
                try:
                    # åŠ è½½ä¸‰ä¸ªæ¨¡æ€
                    csf_img = self._load_and_normalize_image(modalities['CSF'])
                    gray_img = self._load_and_normalize_image(modalities['GRAY'])
                    white_img = self._load_and_normalize_image(modalities['WHITE'])
                    
                    # ç¡®ä¿ä¸‰ä¸ªæ¨¡æ€å½¢çŠ¶ä¸€è‡´
                    if csf_img.shape == gray_img.shape == white_img.shape:
                        # åˆå¹¶ä¸‰ä¸ªæ¨¡æ€ä¸ºä¸€ä¸ªå¤šé€šé“å›¾åƒ [3, D, H, W]
                        multi_modal_img = np.stack([csf_img, gray_img, white_img], axis=0)
                        
                        images.append(multi_modal_img)
                        labels.append(patient_labels[patient_id])
                        patient_ids.append(patient_id)
                    else:
                        print(f"âš ï¸ è­¦å‘Š: æ‚£è€… {patient_id} çš„ä¸‰ä¸ªæ¨¡æ€å½¢çŠ¶ä¸ä¸€è‡´ï¼Œè·³è¿‡")
                except Exception as e:
                    print(f"âš ï¸ è­¦å‘Š: å¤„ç†æ‚£è€… {patient_id} çš„å›¾åƒæ—¶å‡ºé”™: {str(e)}")
            else:
                missing = [key for key in required_keys if key not in modalities]
                print(f"âš ï¸ è­¦å‘Š: æ‚£è€… {patient_id} ç¼ºå°‘æ¨¡æ€: {missing}ï¼Œè·³è¿‡")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        images = np.array(images) if images else np.array([])
        labels = np.array(labels)
        
        print(f"âœ… åŠ è½½å®Œæˆ: {np.sum(labels==1)} æ¢å¤æ‚£è€… + {np.sum(labels==0)} æœªæ¢å¤æ‚£è€… = {len(images)} å›¾åƒ")
        if len(images) > 0:
            print(f"   å›¾åƒå½¢çŠ¶: {images.shape}")
        
        return images, labels, patient_ids
    
    def _load_and_normalize_image(self, file_path):
        """åŠ è½½å¹¶æ ‡å‡†åŒ–å•ä¸ªå›¾åƒ"""
        import nibabel as nib
        from scipy.ndimage import zoom
        
        # åŠ è½½å›¾åƒ
        img = nib.load(file_path).get_fdata()
        
        # ç¡®ä¿å›¾åƒæ˜¯æµ®ç‚¹ç±»å‹
        img = img.astype(np.float32)
        
        # æ ‡å‡†åŒ–åˆ°[0, 1]èŒƒå›´
        if np.max(img) > np.min(img):
            img = (img - np.min(img)) / (np.max(img) - np.min(img))
        
        return img
    
    def _extract_patient_id_from_filename(self, filename):
        """ä»æ–‡ä»¶åä¸­æå–æ‚£è€…ID"""
        # ä¼˜å…ˆåŒ¹é…ç±»ä¼¼002_S_4447æ ¼å¼çš„ID
        match = re.search(r'(\d{3}_S_\d{4})', filename)
        if match:
            return match.group(1)
            
        # å°è¯•å…¶ä»–å¸¸è§æ¨¡å¼
        patterns = [
            r'(\d+)_.*\.nii',  # 123_date.nii
            r'.*_(\d+)_.*\.nii',  # prefix_123_date.nii
            r'.*_(\d+)\.nii',  # prefix_123.nii
            r'(\d+)\.nii'  # 123.nii
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                return match.group(1)
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨æ–‡ä»¶åï¼ˆä¸åŒ…æ‹¬æ‰©å±•åï¼‰ä½œä¸ºID
        return os.path.splitext(filename)[0]
    
    def load_mci_text_data(self):
        """åŠ è½½MCIæ‚£è€…æ–‡æœ¬å…ƒæ•°æ®"""
        print(f"   åŠ è½½ç»“æ„åŒ–MCIå…ƒæ•°æ®...")
        all_texts, all_labels, all_patient_ids = [], [], []
        
        # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.metadata_file):
            print(f"âš ï¸ è­¦å‘Š: MCIå…ƒæ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {self.metadata_file}")
            return [], [], []
        
        try:
            # åŠ è½½å…ƒæ•°æ®
            df = pd.read_excel(self.metadata_file)
            
            # æ ‡å‡†åŒ–åˆ—å
            df.columns = [col.lower() for col in df.columns]
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_cols = ['subject', 'age', 'gender', 'education', 'mmse', 'cdrsb', 'recovery_status']
            if not all(col in df.columns for col in required_cols):
                print(f"âŒ MCIå…ƒæ•°æ®è¡¨ç¼ºå°‘å¿…è¦åˆ—. éœ€è¦: {required_cols}, å®é™…: {list(df.columns)}")
                return [], [], []
            
            for _, row in df.iterrows():
                patient_id = str(row['subject'])
                # æ¢å¤çŠ¶æ€: 1=æ¢å¤, 0=æœªæ¢å¤
                label = 1 if row['recovery_status'] == 'Recovered' else 0
                
                # ç»Ÿä¸€æ€§åˆ«ç¼–ç ï¼š'Male' -> 1, 'Female' -> 0
                gender_code = 1 if isinstance(row['gender'], str) and row['gender'].lower() == 'male' else 0
                        
                # å°†ç»“æ„åŒ–æ•°æ®æ‹¼æ¥æˆä¸€ä¸ªæè¿°æ€§å­—ç¬¦ä¸²
                text = (f"age {row['age']}, gender {gender_code}, education {row['education']}, "
                        f"mmse_score {row['mmse']}, cdrsb_score {row['cdrsb']}")
                
                all_texts.append(text)
                all_labels.append(label)
                all_patient_ids.append(patient_id)
        except Exception as e:
            print(f"âŒ è¯»å–MCIå…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            return [], [], []
        
        print(f"   âœ… æˆåŠŸä¸º {len(all_texts)} åMCIå—è¯•è€…åŠ è½½äº†å…ƒæ•°æ®ã€‚")
        return all_texts, all_labels, all_patient_ids
    
    def align_image_text_data(self, images, texts, image_labels, text_labels, image_patient_ids, text_patient_ids):
        """å¯¹é½å›¾åƒå’Œæ–‡æœ¬æ•°æ® - åŸºäºæ‚£è€…ID"""
        print("ğŸ”„ å¯¹é½å›¾åƒå’Œæ–‡æœ¬æ•°æ®...")
        print(f"   å›¾åƒæ•°æ®: {len(images)} ä¸ªæ ·æœ¬")
        print(f"   æ–‡æœ¬æ•°æ®: {len(texts)} ä¸ªæ ·æœ¬")
        
        # åˆ›å»ºIDåˆ°ç´¢å¼•çš„æ˜ å°„
        image_id_to_idx = {pid: i for i, pid in enumerate(image_patient_ids)}
        text_id_to_idx = {pid: i for i, pid in enumerate(text_patient_ids)}
        
        # æ‰¾åˆ°å…±åŒçš„æ‚£è€…ID
        common_ids = set(image_patient_ids) & set(text_patient_ids)
        
        if not common_ids:
            print("âš ï¸ è­¦å‘Š: å›¾åƒå’Œæ–‡æœ¬æ•°æ®æ²¡æœ‰å…±åŒçš„æ‚£è€…ID")
            print("âš ï¸ æ£€æŸ¥æ‚£è€…IDæ ¼å¼æ˜¯å¦ä¸€è‡´")
            return np.array([]), [], np.array([]), []
        else:
            print(f"âœ… æ‰¾åˆ° {len(common_ids)} ä¸ªå…±åŒæ‚£è€…ID")
            
            # æŒ‰å…±åŒIDé‡æ–°æ’åˆ—æ•°æ®
            aligned_images = []
            aligned_texts = []
            aligned_labels = []
            aligned_patient_ids = []
            
            for pid in common_ids:
                img_idx = image_id_to_idx[pid]
                txt_idx = text_id_to_idx[pid]
                
                aligned_images.append(images[img_idx])
                aligned_texts.append(texts[txt_idx])
                aligned_labels.append(image_labels[img_idx])  # ä½¿ç”¨å›¾åƒæ ‡ç­¾
                aligned_patient_ids.append(pid)
            
            aligned_images = np.array(aligned_images)
            aligned_labels = np.array(aligned_labels)
        
        print(f"âœ… æ•°æ®å¯¹é½å®Œæˆ: {len(aligned_images)} ä¸ªæ ·æœ¬")
        print(f"   æ¢å¤æ‚£è€…: {np.sum(aligned_labels==1)} ä¸ªæ ·æœ¬")
        print(f"   æœªæ¢å¤æ‚£è€…: {np.sum(aligned_labels==0)} ä¸ªæ ·æœ¬")
        
        return aligned_images, aligned_texts, aligned_labels, aligned_patient_ids

class FeatureExtractor:
    """ç‰¹å¾æå–å™¨ - åŸºäºé¢„è®­ç»ƒçš„å¯¹æŠ—æ€§å¯¹æ¯”å­¦ä¹ æ¨¡å‹"""
    
    def __init__(self, model_path, device='cuda', batch_size=16):
        self.device = device
        self.model_path = model_path
        self.batch_size = batch_size
        
        print(f"ğŸ”§ åˆå§‹åŒ–ç‰¹å¾æå–å™¨...")
        print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"   è®¾å¤‡: {device}")
        
        # åŠ è½½å›¾åƒç¼–ç å™¨
        self.image_encoder = self._load_pretrained_image_model()
        self.image_encoder.to(self.device)
        self.image_encoder.eval()

        # åŠ¨æ€æ£€æµ‹å›¾åƒç‰¹å¾ç»´åº¦
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 113, 137, 113).to(self.device)
            dummy_output = self.image_encoder(dummy_input, return_features=True)
            image_output_dim = dummy_output.shape[1]
            print(f"ğŸ”§ æ£€æµ‹åˆ°å›¾åƒç¼–ç å™¨è¾“å‡ºç»´åº¦: {image_output_dim}")

        # åˆ›å»ºç‰¹å¾è°ƒæ•´å±‚ï¼Œç¡®ä¿è¾“å‡ºç»´åº¦ä¸º512
        if image_output_dim != 512:
            print(f"   âš ï¸ è¾“å‡ºç»´åº¦ä¸æ˜¯512ï¼Œæ·»åŠ å›¾åƒç‰¹å¾è°ƒæ•´å±‚ {image_output_dim} -> 512")
            self.image_feature_adjust = nn.Sequential(
                nn.Linear(image_output_dim, 512),
                nn.ReLU(),
            ).to(self.device)
        else:
            self.image_feature_adjust = nn.Identity()

        # åˆå§‹åŒ–æ–‡æœ¬ç¼–ç å™¨
        self.text_encoder = AdversarialTextEncoder(
            feature_dim=512, 
            device=self.device
        )
        self.text_encoder.to(self.device)
        self.text_encoder.eval()

        print(f"ç‰¹å¾æå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_pretrained_image_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„å›¾åƒæ¨¡å‹"""
        print(f"ğŸ”„ æ™ºèƒ½åŠ è½½é¢„è®­ç»ƒå›¾åƒæ¨¡å‹...")
        
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {self.model_path}")
        
        try:
            from optimized_models import ImprovedResNetCBAM3D
        except ImportError:
            raise ImportError("âŒ æ— æ³•å¯¼å…¥ImprovedResNetCBAM3Dæ¨¡å‹ç±»ï¼Œè¯·ç¡®ä¿optimized_models.pyåœ¨è·¯å¾„ä¸­")

        checkpoint = torch.load(self.model_path, map_location=self.device)
        state_dict = checkpoint.get('model_state_dict', checkpoint)
        
        # æ£€æµ‹åŸºç¡€é€šé“æ•°
        base_channels = 12
        if 'stem.0.weight' in state_dict and state_dict['stem.0.weight'].shape[0] == 4:
            base_channels = 8
        elif 'image_encoder.backbone.stem.0.weight' in state_dict and state_dict['image_encoder.backbone.stem.0.weight'].shape[0] == 4:
            base_channels = 8
            
        # åˆ›å»ºæ¨¡å‹
        model = ImprovedResNetCBAM3D(
            in_channels=3, num_classes=2, base_channels=base_channels, 
            dropout_rate=0.3, use_global_pool=False
        )
        
        keys = list(state_dict.keys())
        
        # å¤„ç†ä¸åŒç±»å‹çš„æ£€æŸ¥ç‚¹
        if any(k.startswith('image_encoder.backbone.') for k in keys):
            print("   ğŸ”§ æ£€æµ‹åˆ°å®Œæ•´çš„å¯¹æŠ—æ€§æ¨¡å‹æ£€æŸ¥ç‚¹")
            temp_state_dict = {}
            prefix = 'image_encoder.backbone.'
            for key, value in state_dict.items():
                if key.startswith(prefix):
                    new_key = key[len(prefix):]
                    temp_state_dict[new_key] = value
            backbone_state_dict = {
                k: v for k, v in temp_state_dict.items() 
                if not k.startswith('fusion') and not k.startswith('classifier')
            }
            model.load_state_dict(backbone_state_dict, strict=False)
        else:
            print("   ğŸ”§ æ£€æµ‹åˆ°ç‹¬ç«‹çš„å›¾åƒç¼–ç å™¨æ£€æŸ¥ç‚¹")
            backbone_state_dict = {
                k: v for k, v in state_dict.items() 
                if not k.startswith('fusion') and not k.startswith('classifier')
            }
            model.load_state_dict(backbone_state_dict, strict=False)

        return model
    
    def extract_image_features(self, images):
        """æå–å›¾åƒç‰¹å¾"""
        print(f"ğŸ–¼ æå–å›¾åƒç‰¹å¾: {images.shape}")
        
        if len(images) == 0:
            return np.empty((0, 512))
            
        features_list = []
        with torch.no_grad():
            for i in tqdm(range(0, len(images), self.batch_size), desc="æå–å›¾åƒç‰¹å¾"):
                batch_images = images[i:i+self.batch_size]
                batch_tensor = torch.FloatTensor(batch_images).to(self.device)
                image_features = self.image_encoder(batch_tensor, return_features=True)
                
                # åº”ç”¨ç‰¹å¾ç»´åº¦é€‚é…å±‚
                adjusted_features = self.image_feature_adjust(image_features)
                
                features_list.append(adjusted_features.cpu().numpy())
            
        features = np.concatenate(features_list, axis=0)
        return features
            
    def extract_text_features(self, texts):
        """æå–æ–‡æœ¬ç‰¹å¾"""
        print(f"ğŸ“ æå–æ–‡æœ¬ç‰¹å¾: {len(texts)} ä¸ªæ–‡æœ¬")
        
        if not texts:
            return np.empty((0, 512))
        
        features_list = []
        with torch.no_grad():
            for i in tqdm(range(0, len(texts), self.batch_size), desc="æå–æ–‡æœ¬ç‰¹å¾"):
                batch_texts = texts[i:i+self.batch_size]
                text_features = self.text_encoder(batch_texts)
                features_list.append(text_features.cpu().numpy())

        features = np.concatenate(features_list, axis=0)
        return features
    
    def extract_multimodal_features(self, images, texts, fusion_strategy='image_only', feature_noise_std=0.0):
        """æå–å¤šæ¨¡æ€ç‰¹å¾"""
        print(f"ğŸ”„ æå–å¤šæ¨¡æ€ç‰¹å¾ (ç­–ç•¥: {fusion_strategy})...")
            
        # æå–å›¾åƒç‰¹å¾
        image_features = self.extract_image_features(images)
        
        # æå–æ–‡æœ¬ç‰¹å¾
        text_features = self.extract_text_features(texts)
        
        # æ·»åŠ ç‰¹å¾å™ªå£°ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if feature_noise_std > 0:
            np.random.seed(RANDOM_SEED)
            image_noise = np.random.normal(0, feature_noise_std, image_features.shape)
            image_features = image_features + image_noise
            print(f"   æ·»åŠ ç‰¹å¾å™ªå£°: std={feature_noise_std}")

        print(f"ğŸ”§ ç‰¹å¾æå–å®Œæˆ:")
        print(f"   å›¾åƒç‰¹å¾å½¢çŠ¶: {image_features.shape}")
        
        # æ ¹æ®èåˆç­–ç•¥è¿”å›ç‰¹å¾
        if fusion_strategy == 'image_only':
            return image_features
        elif fusion_strategy == 'text_only':
            return text_features
        elif fusion_strategy == 'concatenate':
            return np.concatenate((image_features, text_features), axis=1)
        elif fusion_strategy == 'weighted_average':
            # é»˜è®¤æƒé‡ï¼šå›¾åƒ0.7ï¼Œæ–‡æœ¬0.3
            return 0.7 * image_features + 0.3 * text_features
        else:
            raise ValueError(f"æœªçŸ¥çš„èåˆç­–ç•¥: {fusion_strategy}")

class MCIRecoveryClassifier:
    """MCIæ¢å¤åˆ†ç±»å™¨ï¼Œç”¨äºé¢„æµ‹MCIæ‚£è€…æ˜¯å¦ä¼šæ¢å¤ä¸ºè®¤çŸ¥æ­£å¸¸"""
    
    def __init__(self, config=None):
        self.config = config or RECOMMENDED_CONFIG
        self.classifier_type = self.config.get('classifier_type', 'xgb')
        self.feature_standardization = self.config.get('feature_standardization', True)
        self.scaler = StandardScaler() if self.feature_standardization else None
        
        print(f"ğŸ”§ åˆå§‹åŒ–MCIæ¢å¤åˆ†ç±»å™¨...")
        print(f"   åˆ†ç±»å™¨ç±»å‹: {self.classifier_type}")
        print(f"   ç‰¹å¾æ ‡å‡†åŒ–: {self.feature_standardization}")
    
    def _create_classifier(self):
        """åˆ›å»ºåˆ†ç±»å™¨å®ä¾‹"""
        if self.classifier_type == 'logistic':
            return LogisticRegression(
                C=self.config.get('regularization_strength', 1.0),
                max_iter=self.config.get('max_iter', 6000),
                random_state=RANDOM_SEED
            )
        elif self.classifier_type == 'svm':
            return SVC(
                C=self.config.get('regularization_strength', 1.0),
                kernel='rbf',
                probability=True,
                random_state=RANDOM_SEED
            )
        elif self.classifier_type == 'random_forest':
            return RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                random_state=RANDOM_SEED
            )
        elif self.classifier_type == 'gradient_boosting':
            return GradientBoostingClassifier(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=5,
                random_state=RANDOM_SEED
            )
        elif self.classifier_type == 'xgb':
            return xgb.XGBClassifier(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=5,
                reg_lambda=self.config.get('regularization_strength', 1.0),
                use_label_encoder=False,
                eval_metric='logloss',
                random_state=RANDOM_SEED
            )
        else:
            raise ValueError(f"æœªçŸ¥çš„åˆ†ç±»å™¨ç±»å‹: {self.classifier_type}")
    
    def train_and_evaluate(self, features, labels, patient_ids=None):
        """è®­ç»ƒå¹¶è¯„ä¼°MCIæ¢å¤åˆ†ç±»å™¨"""
        print(f"ğŸ”„ å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°MCIæ¢å¤åˆ†ç±»å™¨...")
        start_time = time.time()
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        if self.feature_standardization:
            features = self.scaler.fit_transform(features)
        
        # äº¤å‰éªŒè¯ç±»å‹
        cross_validation = self.config.get('cross_validation', 'kfold')
        
        if cross_validation == 'kfold':
            # KæŠ˜äº¤å‰éªŒè¯
            kfold_splits = self.config.get('kfold_splits', 5)
            kf = KFold(n_splits=kfold_splits, shuffle=True, random_state=RANDOM_SEED)
            
            all_preds = np.zeros_like(labels, dtype=float)
            all_probs = np.zeros_like(labels, dtype=float)
            fold_results = []
            
            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(features, labels)):
                print(f"\n   ğŸ“Š ç¬¬ {fold_idx + 1}/{kfold_splits} æŠ˜äº¤å‰éªŒè¯")
                
                # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
                X_train, X_val = features[train_idx], features[val_idx]
                y_train, y_val = labels[train_idx], labels[val_idx]
                
                # åˆ›å»ºå¹¶è®­ç»ƒåˆ†ç±»å™¨
                classifier = self._create_classifier()
                classifier.fit(X_train, y_train)
                
                # é¢„æµ‹
                y_pred = classifier.predict(X_val)
                y_prob = classifier.predict_proba(X_val)[:, 1] if hasattr(classifier, 'predict_proba') else classifier.decision_function(X_val)
                
                # ä¿å­˜ç»“æœ
                all_preds[val_idx] = y_pred
                all_probs[val_idx] = y_prob
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                fold_result = self._calculate_metrics(y_val, y_pred, y_prob)
                fold_results.append(fold_result)
                
                print(f"   å‡†ç¡®ç‡: {fold_result['accuracy']:.4f}")
                print(f"   ç²¾ç¡®ç‡: {fold_result['precision']:.4f}")
                print(f"   å¬å›ç‡: {fold_result['recall']:.4f}")
                print(f"   F1åˆ†æ•°: {fold_result['f1']:.4f}")
                print(f"   AUC: {fold_result['auc']:.4f}")
            
            # è®¡ç®—å¹³å‡ç»“æœ
            avg_results = self._calculate_average_results(fold_results)
            print(f"\nğŸ“‹ å¹³å‡äº¤å‰éªŒè¯ç»“æœ:")
            for metric, value in avg_results.items():
                print(f"   {metric}: {value:.4f}")
            
            # è®¡ç®—æ€»ä½“ç»“æœ
            overall_results = self._calculate_metrics(labels, all_preds, all_probs)
            print(f"\nğŸ“Š æ€»ä½“ç»“æœ:")
            for metric, value in overall_results.items():
                print(f"   {metric}: {value:.4f}")
            
            # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
            print(f"\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
            print(classification_report(labels, all_preds, target_names=['æœªæ¢å¤', 'æ¢å¤']))
            
            # ç”Ÿæˆæ··æ·†çŸ©é˜µ
            self._plot_confusion_matrix(labels, all_preds)
            
            # ç”ŸæˆROCæ›²çº¿
            self._plot_roc_curve(labels, all_probs)
        
        elapsed_time = time.time() - start_time
        print(f"\nâœ… è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
        
        return {
            'fold_results': fold_results,
            'avg_results': avg_results,
            'overall_results': overall_results,
            'predictions': all_preds,
            'probabilities': all_probs
        }
    
    def _calculate_metrics(self, y_true, y_pred, y_prob):
        """è®¡ç®—åˆ†ç±»æ€§èƒ½æŒ‡æ ‡"""
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='binary')
        recall = recall_score(y_true, y_pred, average='binary')
        f1 = f1_score(y_true, y_pred, average='binary')
        
        # è®¡ç®—AUC
        try:
            auc = roc_auc_score(y_true, y_prob)
        except ValueError:
            auc = 0.0
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc': auc
        }
    
    def _calculate_average_results(self, fold_results):
        """è®¡ç®—å¹³å‡äº¤å‰éªŒè¯ç»“æœ"""
        avg_results = {}
        metrics = fold_results[0].keys()
        
        for metric in metrics:
            avg_results[metric] = np.mean([fold[metric] for fold in fold_results])
            avg_results[f'{metric}_std'] = np.std([fold[metric] for fold in fold_results])
        
        return avg_results
    
    def _plot_confusion_matrix(self, y_true, y_pred):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                  xticklabels=['æœªæ¢å¤', 'æ¢å¤'], 
                  yticklabels=['æœªæ¢å¤', 'æ¢å¤'])
        plt.title('MCIæ¢å¤é¢„æµ‹æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        
        # ä¿å­˜æ··æ·†çŸ©é˜µ
        os.makedirs('./results', exist_ok=True)
        plt.savefig('./results/confusion_matrix.png')
        print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ° ./results/confusion_matrix.png")
        plt.close()
    
    def _plot_roc_curve(self, y_true, y_prob):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        fpr, tpr, _ = roc_curve(y_true, y_prob)
        roc_auc = roc_auc_score(y_true, y_prob)
        
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('å‡é˜³æ€§ç‡')
        plt.ylabel('çœŸé˜³æ€§ç‡')
        plt.title('MCIæ¢å¤é¢„æµ‹ROCæ›²çº¿')
        plt.legend(loc="lower right")
        
        # ä¿å­˜ROCæ›²çº¿
        os.makedirs('./results', exist_ok=True)
        plt.savefig('./results/roc_curve.png')
        print(f"âœ… ROCæ›²çº¿å·²ä¿å­˜åˆ° ./results/roc_curve.png")
        plt.close()
    
    def predict(self, features):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„åˆ†ç±»å™¨è¿›è¡Œé¢„æµ‹"""
        # æ ‡å‡†åŒ–ç‰¹å¾
        if self.feature_standardization:
            features = self.scaler.transform(features)
        
        # é¢„æµ‹
        y_pred = self.classifier.predict(features)
        y_prob = self.classifier.predict_proba(features)[:, 1] if hasattr(self.classifier, 'predict_proba') else self.classifier.decision_function(features)
        
        return y_pred, y_prob
    
    def save_model(self, save_path):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        import pickle
        
        model_data = {
            'classifier': self.classifier,
            'config': self.config,
            'scaler': self.scaler
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_model(self, load_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        import pickle
        
        with open(load_path, 'rb') as f:
            model_data = pickle.load(f)
        
        self.classifier = model_data['classifier']
        self.config = model_data.get('config', self.config)
        self.scaler = model_data.get('scaler', None)
        
        print(f"âœ… æ¨¡å‹å·²ä»: {load_path} åŠ è½½")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MCIæ¢å¤é¢„æµ‹ç³»ç»Ÿ")
    parser.add_argument('--data_dir', type=str, default='/root/autodl-tmp/DATA_MCI/', help='MCIæ•°æ®ç›®å½•')
    parser.add_argument('--model_path', type=str, default='./models/adversarial/best_mcic_adversarial_cv_model.pth', help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--config', type=str, default=None, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--save_results', type=bool, default=True, help='æ˜¯å¦ä¿å­˜ç»“æœ')
    parser.add_argument('--fusion_strategy', type=str, default='image_only', help='ç‰¹å¾èåˆç­–ç•¥')
    parser.add_argument('--classifier_type', type=str, default='xgb', help='åˆ†ç±»å™¨ç±»å‹')
    parser.add_argument('--cross_validation', type=str, default='kfold', help='äº¤å‰éªŒè¯ç±»å‹')
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_seed()
    
    # åŠ è½½é…ç½®
    config = RECOMMENDED_CONFIG
    if args.config:
        import json
        with open(args.config, 'r') as f:
            config.update(json.load(f))
    
    # æ›´æ–°é…ç½®
    config['fusion_strategy'] = args.fusion_strategy
    config['classifier_type'] = args.classifier_type
    config['cross_validation'] = args.cross_validation
    
    # è®¾å¤‡é€‰æ‹©
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    data_loader = MCIDataLoader(args.data_dir)
    images, labels, patient_ids = data_loader.load_mci_images()
    
    if len(images) == 0:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•å›¾åƒæ•°æ®ï¼Œé€€å‡ºç¨‹åº")
        return
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    feature_extractor = FeatureExtractor(args.model_path, device=device)
    
    # æå–ç‰¹å¾
    features = feature_extractor.extract_multimodal_features(images, [], fusion_strategy=args.fusion_strategy)
    
    # åˆ›å»ºå¹¶è®­ç»ƒåˆ†ç±»å™¨
    classifier = MCIRecoveryClassifier(config)
    results = classifier.train_and_evaluate(features, labels, patient_ids)
    
    # ä¿å­˜ç»“æœ
    if args.save_results:
        os.makedirs('./results', exist_ok=True)
        results_file = f'./results/mci_recovery_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        import json
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=4, default=lambda x: float(x) if isinstance(x, np.float32) else x.tolist() if isinstance(x, np.ndarray) else str(x))
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    print("\nğŸ‰ MCIæ¢å¤é¢„æµ‹å®Œæˆï¼")

if __name__ == '__main__':
    main()
