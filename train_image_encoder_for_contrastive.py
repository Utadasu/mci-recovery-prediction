#!/usr/bin/env python3
"""
ğŸ”¥ å¯¹æ¯”å­¦ä¹ å›¾åƒç¼–ç å™¨é¢„è®­ç»ƒè„šæœ¬
===============================

åŠŸèƒ½ç‰¹æ€§:
- ğŸ¯ ä¸“é—¨ä¸ºå¯¹æ¯”å­¦ä¹ ç³»ç»Ÿè®­ç»ƒå›¾åƒç¼–ç å™¨
- ğŸ§  ä½¿ç”¨æ™ºèƒ½ä¸‹é‡‡æ ·å±‚ImprovedResNetCBAM3Dæ¶æ„
- ğŸ“Š è¾“å‡º512ç»´ç‰¹å¾ï¼Œä¸æ–‡æœ¬ç¼–ç å™¨å¯¹é½
- ğŸ’¾ ä¿å­˜åˆ°å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒè·¯å¾„
- ğŸ”§ ä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥å’Œå‚æ•°
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import json
from tqdm import tqdm
from datetime import datetime
import matplotlib.pyplot as plt

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from optimized_models import ImprovedResNetCBAM3D
from data_utils import load_early_fusion_data
from losses import ImprovedFocalLoss

# CUDAä¼˜åŒ–è®¾ç½®
torch.cuda.set_per_process_memory_fraction(0.95)
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

def get_default_data_path():
    """è·å–é»˜è®¤æ•°æ®è·¯å¾„"""
    # æœåŠ¡å™¨é»˜è®¤è·¯å¾„
    server_path = "/root/autodl-tmp/DATA_MCI/test_data/"
    if os.path.exists(server_path):
        return server_path
    
    # æ–°é¡¹ç›®è·¯å¾„ä¸‹çš„æœ¬åœ°è°ƒè¯•è·¯å¾„
    new_project_paths = [
        "/autodl-fs/data/ZM_Files/å¤‡ä»½5.27/test_data/",
        "/autodl-fs/data/ZM_Files/å¤‡ä»½5.27/../test_data/",
        "/autodl-fs/data/test_data/"
    ]
    
    for path in new_project_paths:
        if os.path.exists(path):
            return path
    
    # åŸæœ‰æœ¬åœ°è°ƒè¯•è·¯å¾„
    local_paths = [
        "./test_data/",
        "../test_data/",
        "../../test_data/"
    ]
    
    for path in local_paths:
        if os.path.exists(path):
            return path
    
    return server_path

class ContrastiveImageEncoderTrainer:
    """
    å¯¹æ¯”å­¦ä¹ å›¾åƒç¼–ç å™¨è®­ç»ƒå™¨
    ä¸“é—¨ä¸ºå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ç³»ç»Ÿè®­ç»ƒå›¾åƒç¼–ç å™¨
    """
    def __init__(self, device='cuda'):
        self.device = device
        
        # ğŸ”¥ å¯¹æ¯”å­¦ä¹ ä¸“ç”¨ä¿å­˜è·¯å¾„
        self.save_dir = './models/contrastive'
        os.makedirs(self.save_dir, exist_ok=True)
        
        # è®­ç»ƒå†å²è®°å½•
        self.train_history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': [],
            'epochs': []
        }
        
        print(f"ğŸš€ ContrastiveImageEncoderTrainer åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {device}")
        print(f"   ä¿å­˜ç›®å½•: {self.save_dir}")
        print(f"   ç›®æ ‡: ä¸ºå¯¹æ¯”å­¦ä¹ ç³»ç»Ÿè®­ç»ƒå›¾åƒç¼–ç å™¨")
    
    def create_contrastive_image_model(self, base_channels=12, use_cbam=True):
        """
        åˆ›å»ºå¯¹æ¯”å­¦ä¹ ä¸“ç”¨çš„å›¾åƒç¼–ç å™¨æ¨¡å‹
        
        Args:
            base_channels: åŸºç¡€é€šé“æ•°
            use_cbam: æ˜¯å¦ä½¿ç”¨CBAMæ³¨æ„åŠ›æ¨¡å—
        """
        print(f"\nğŸ”§ åˆ›å»ºå¯¹æ¯”å­¦ä¹ å›¾åƒç¼–ç å™¨...")
        print(f"   æ¶æ„: ImprovedResNetCBAM3D + æ™ºèƒ½ä¸‹é‡‡æ ·å±‚")
        print(f"   åŸºç¡€é€šé“æ•°: {base_channels}")
        print(f"   ä½¿ç”¨CBAM: {'âœ…' if use_cbam else 'âŒ'}")
        print(f"   è¾“å‡ºç‰¹å¾: 512ç»´ (ä¸æ–‡æœ¬ç¼–ç å™¨å¯¹é½)")
        
        # åˆ›å»ºä½¿ç”¨æ™ºèƒ½ä¸‹é‡‡æ ·å±‚çš„æ¨¡å‹
        model = ImprovedResNetCBAM3D(
            in_channels=3,
            num_classes=2,  # AD vs CN
            base_channels=base_channels,
            dropout_rate=0.3,
            use_global_pool=False,  # ğŸ”¥ ä½¿ç”¨æ™ºèƒ½ä¸‹é‡‡æ ·å±‚
            use_cbam=use_cbam  # ä¼ é€’CBAMå¼€å…³
        ).to(self.device)
        
        # ä¿®æ”¹fusionå±‚ï¼Œè¾“å‡º512ç»´ç‰¹å¾ä»¥åŒ¹é…æ–‡æœ¬ç¼–ç å™¨
        fusion_input_dim = base_channels * 16 * 2 * 2 * 2  # æ™ºèƒ½ä¸‹é‡‡æ ·å±‚è¾“å‡ºç»´åº¦
        
        model.fusion = nn.Sequential(
            nn.Linear(fusion_input_dim, 1024),
            nn.LayerNorm(1024),
            nn.ReLU(inplace=False),
            nn.Dropout(0.3),
            
            nn.Linear(1024, 512),  # ğŸ¯ è¾“å‡º512ç»´ç‰¹å¾
            nn.LayerNorm(512),
            nn.ReLU(inplace=False),
            nn.Dropout(0.3)
        ).to(self.device)
        
        # ä¿ç•™åˆ†ç±»å¤´ç”¨äºé¢„è®­ç»ƒ
        model.classifier = nn.Linear(512, 2).to(self.device)
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"   æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   ç‰¹å¾ç»´åº¦: {fusion_input_dim} â†’ 1024 â†’ 512")
        
        return model
    
    def prepare_data(self, data_path, batch_size=4, max_samples=None):
        """å‡†å¤‡è®­ç»ƒæ•°æ® - æ”¹è¿›ç‰ˆæœ¬ï¼Œç¡®ä¿æ‚£è€…çº§åˆ«åˆ†å‰²"""
        print(f"\nğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        print(f"   æ•°æ®è·¯å¾„: {data_path}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        # åŠ è½½æ—©æœŸèåˆæ•°æ®
        image_data, labels = load_early_fusion_data(data_path, max_samples=max_samples)
        
        print(f"   å›¾åƒæ•°æ®å½¢çŠ¶: {image_data.shape}")
        print(f"   æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
        print(f"   ADæ ·æœ¬æ•°: {np.sum(labels==1)}")
        print(f"   CNæ ·æœ¬æ•°: {np.sum(labels==0)}")
        
        # ğŸ”¥ æ”¹è¿›ï¼šæ‚£è€…çº§åˆ«æ•°æ®åˆ†å‰²ï¼Œé¿å…æ•°æ®æ³„éœ²
        # å‡è®¾æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ˜¯æŒ‰æ‚£è€…é¡ºåºæ’åˆ—çš„
        ad_indices = np.where(labels == 1)[0]
        cn_indices = np.where(labels == 0)[0]
        
        # æ‚£è€…çº§åˆ«åˆ†å‰² - å‡è®¾æ¯ä¸ªæ‚£è€…æœ‰å¤šä¸ªæ‰«æ
        # ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬æŒ‰ç´¢å¼•åˆ†ç»„æ¥æ¨¡æ‹Ÿæ‚£è€…åˆ†å‰²
        def patient_level_split(indices, train_ratio=0.8):
            """æ‚£è€…çº§åˆ«åˆ†å‰²"""
            n_samples = len(indices)
            # å‡è®¾æ¯10ä¸ªæ ·æœ¬æ¥è‡ªåŒä¸€æ‚£è€…ï¼ˆè¿™æ˜¯ä¸€ä¸ªç®€åŒ–å‡è®¾ï¼‰
            patient_size = 10
            n_patients = n_samples // patient_size
            
            # éšæœºæ‰“ä¹±æ‚£è€…é¡ºåº
            patient_indices = np.arange(n_patients)
            np.random.seed(42)  # å›ºå®šéšæœºç§å­
            np.random.shuffle(patient_indices)
            
            # åˆ†å‰²æ‚£è€…
            n_train_patients = int(n_patients * train_ratio)
            train_patients = patient_indices[:n_train_patients]
            val_patients = patient_indices[n_train_patients:]
            
            # è·å–å¯¹åº”çš„æ ·æœ¬ç´¢å¼•
            train_indices = []
            val_indices = []
            
            for p in train_patients:
                start_idx = p * patient_size
                end_idx = min((p + 1) * patient_size, n_samples)
                train_indices.extend(indices[start_idx:end_idx])
            
            for p in val_patients:
                start_idx = p * patient_size
                end_idx = min((p + 1) * patient_size, n_samples)
                val_indices.extend(indices[start_idx:end_idx])
            
            return train_indices, val_indices
        
        # åˆ†åˆ«å¯¹ADå’ŒCNè¿›è¡Œæ‚£è€…çº§åˆ«åˆ†å‰²
        ad_train_indices, ad_val_indices = patient_level_split(ad_indices, train_ratio=0.8)
        cn_train_indices, cn_val_indices = patient_level_split(cn_indices, train_ratio=0.8)
        
        # åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†ç´¢å¼•
        train_indices = ad_train_indices + cn_train_indices
        val_indices = ad_val_indices + cn_val_indices
        
        # æ‰“ä¹±è®­ç»ƒé›†ç´¢å¼•
        np.random.seed(42)
        np.random.shuffle(train_indices)
        np.random.shuffle(val_indices)
        
        print(f"   ğŸ”„ æ‚£è€…çº§åˆ«åˆ†å‰²ç»“æœ:")
        print(f"     è®­ç»ƒé›†: {len(train_indices)} æ ·æœ¬")
        print(f"     éªŒè¯é›†: {len(val_indices)} æ ·æœ¬")
        print(f"     è®­ç»ƒé›†AD: {np.sum(labels[train_indices] == 1)}")
        print(f"     è®­ç»ƒé›†CN: {np.sum(labels[train_indices] == 0)}")
        print(f"     éªŒè¯é›†AD: {np.sum(labels[val_indices] == 1)}")
        print(f"     éªŒè¯é›†CN: {np.sum(labels[val_indices] == 0)}")
        
        # åˆ›å»ºæ•°æ®é›†
        from torch.utils.data import TensorDataset, Subset
        
        # åˆ›å»ºPyTorchå¼ é‡
        image_tensor = torch.FloatTensor(image_data)
        label_tensor = torch.LongTensor(labels)
        
        # åˆ›å»ºå®Œæ•´æ•°æ®é›†
        full_dataset = TensorDataset(image_tensor, label_tensor)
        
        # åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
        train_dataset = Subset(full_dataset, train_indices)
        val_dataset = Subset(full_dataset, val_indices)
        
        # ğŸ”§ æ”¹è¿›ï¼šä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ä½¿ç”¨ä¸åŒçš„æ•°æ®åŠ è½½ç­–ç•¥
        # è®­ç»ƒé›†ï¼šä½¿ç”¨æ•°æ®å¢å¼ºï¼Œè¾ƒå°batch size
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=2,
            pin_memory=False,
            drop_last=True  # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„batch
        )
        
        # éªŒè¯é›†ï¼šä¸ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œå¯ä»¥ä½¿ç”¨ç¨å¤§çš„batch size
        val_batch_size = min(batch_size * 2, 8)  # éªŒè¯æ—¶å¯ä»¥ç”¨æ›´å¤§çš„batch
        val_loader = DataLoader(
            val_dataset,
            batch_size=val_batch_size,
            shuffle=False,  # éªŒè¯é›†ä¸éœ€è¦æ‰“ä¹±
            num_workers=2,
            pin_memory=False,
            drop_last=False
        )
        
        print(f"   è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        print(f"   éªŒè¯é›†å¤§å°: {len(val_dataset)}")
        print(f"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"   éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        
        return train_loader, val_loader
    
    def train_epoch(self, model, train_loader, optimizer, criterion, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch:02d} [Train]")
        
        for batch_idx, (data, target) in enumerate(progress_bar):
            data, target = data.to(self.device), target.to(self.device)
            
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            output = model(data)
            loss = criterion(output, target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100.*correct/total:.2f}%'
            })
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100. * correct / total
        
        return avg_loss, accuracy
    
    def validate_epoch(self, model, val_loader, criterion, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            progress_bar = tqdm(val_loader, desc=f"Epoch {epoch:02d} [Val]")
            
            for data, target in progress_bar:
                data, target = data.to(self.device), target.to(self.device)
                
                output = model(data)
                loss = criterion(output, target)
                
                total_loss += loss.item()
                _, predicted = output.max(1)
                total += target.size(0)
                correct += predicted.eq(target).sum().item()
                
                progress_bar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{100.*correct/total:.2f}%'
                })
        
        avg_loss = total_loss / len(val_loader)
        accuracy = 100. * correct / total
        
        return avg_loss, accuracy
    
    def train(self, data_path, base_channels=12, num_epochs=50, batch_size=4, 
              learning_rate=1e-4, max_samples=None, patience=15):
        """
        ä¸»è®­ç»ƒå‡½æ•° - æ”¹è¿›ç‰ˆæœ¬ï¼Œæ·»åŠ è¿‡æ‹Ÿåˆæ£€æµ‹å’Œæ­£åˆ™åŒ–
        
        Args:
            data_path: æ•°æ®è·¯å¾„
            base_channels: åŸºç¡€é€šé“æ•°
            num_epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            max_samples: æœ€å¤§æ ·æœ¬æ•°
            patience: æ—©åœè€å¿ƒå€¼
        """
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒå¯¹æ¯”å­¦ä¹ å›¾åƒç¼–ç å™¨")
        print(f"   ç›®æ ‡: ä¸ºå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ç³»ç»Ÿæä¾›é¢„è®­ç»ƒå›¾åƒç¼–ç å™¨")
        print(f"   è®­ç»ƒè½®æ•°: {num_epochs}")
        print(f"   å­¦ä¹ ç‡: {learning_rate}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"   æ—©åœè€å¿ƒ: {patience}")
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_contrastive_image_model(base_channels)
        
        # å‡†å¤‡æ•°æ®
        train_loader, val_loader = self.prepare_data(data_path, batch_size, max_samples)
        
        # ğŸ”§ æ”¹è¿›ï¼šæ›´å¼ºçš„æ­£åˆ™åŒ–ç­–ç•¥
        criterion = ImprovedFocalLoss(alpha=1.0, gamma=2.0, reduction='mean')
        
        # ä½¿ç”¨æ›´å¼ºçš„æƒé‡è¡°å‡
        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=5e-4)
        
        # æ”¹è¿›çš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=5, verbose=True, min_lr=1e-6
        )
        
        # è®­ç»ƒè®°å½•
        best_val_acc = 0.0
        patience_counter = 0
        best_model_path = None
        
        # ğŸš¨ è¿‡æ‹Ÿåˆæ£€æµ‹å‚æ•°
        overfitting_threshold = 10.0  # éªŒè¯å‡†ç¡®ç‡æ¯”è®­ç»ƒå‡†ç¡®ç‡é«˜å‡º10%å°±è®¤ä¸ºå¯èƒ½è¿‡æ‹Ÿåˆ
        consecutive_overfitting = 0
        max_consecutive_overfitting = 3
        
        print(f"\nğŸ“ˆ å¼€å§‹è®­ç»ƒå¾ªç¯...")
        print(f"ğŸš¨ è¿‡æ‹Ÿåˆæ£€æµ‹: å½“éªŒè¯å‡†ç¡®ç‡æŒç»­æ¯”è®­ç»ƒå‡†ç¡®ç‡é«˜{overfitting_threshold}%æ—¶å°†è§¦å‘è­¦å‘Š")
        
        for epoch in range(1, num_epochs + 1):
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_acc = self.train_epoch(model, train_loader, optimizer, criterion, epoch)
            
            # éªŒè¯é˜¶æ®µ
            val_loss, val_acc = self.validate_epoch(model, val_loader, criterion, epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦ - åŸºäºéªŒè¯å‡†ç¡®ç‡
            scheduler.step(val_acc)
            current_lr = optimizer.param_groups[0]['lr']
            
            # è®°å½•å†å²
            self.train_history['train_loss'].append(train_loss)
            self.train_history['train_acc'].append(train_acc)
            self.train_history['val_loss'].append(val_loss)
            self.train_history['val_acc'].append(val_acc)
            self.train_history['epochs'].append(epoch)
            
            # ğŸš¨ è¿‡æ‹Ÿåˆæ£€æµ‹
            acc_diff = val_acc - train_acc
            if acc_diff > overfitting_threshold:
                consecutive_overfitting += 1
                print(f"  ğŸš¨ è¿‡æ‹Ÿåˆè­¦å‘Š: éªŒè¯å‡†ç¡®ç‡æ¯”è®­ç»ƒå‡†ç¡®ç‡é«˜ {acc_diff:.2f}% (è¿ç»­{consecutive_overfitting}æ¬¡)")
                
                if consecutive_overfitting >= max_consecutive_overfitting:
                    print(f"  âš ï¸  æ£€æµ‹åˆ°ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œå»ºè®®æ£€æŸ¥æ•°æ®åˆ†å‰²æˆ–å¢åŠ æ­£åˆ™åŒ–")
            else:
                consecutive_overfitting = 0
            
            # æ‰“å°ç»“æœ
            print(f"\nEpoch {epoch:02d}/{num_epochs}:")
            print(f"  è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
            print(f"  éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")
            print(f"  å‡†ç¡®ç‡å·®å¼‚: {acc_diff:+.2f}% (éªŒè¯-è®­ç»ƒ)")
            print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")
            
            # ğŸ”§ æ”¹è¿›çš„æ¨¡å‹ä¿å­˜ç­–ç•¥ï¼šè€ƒè™‘è¿‡æ‹Ÿåˆæƒ…å†µ
            save_model = False
            
            if val_acc > best_val_acc:
                # å¦‚æœéªŒè¯å‡†ç¡®ç‡æå‡ï¼Œä½†è¦æ£€æŸ¥æ˜¯å¦è¿‡æ‹Ÿåˆä¸¥é‡
                if acc_diff <= overfitting_threshold * 1.5:  # å…è®¸é€‚åº¦çš„éªŒè¯å‡†ç¡®ç‡ä¼˜åŠ¿
                    save_model = True
                    best_val_acc = val_acc
                    patience_counter = 0
                else:
                    print(f"  âš ï¸  éªŒè¯å‡†ç¡®ç‡æå‡ä½†ç–‘ä¼¼è¿‡æ‹Ÿåˆä¸¥é‡ï¼Œä¸ä¿å­˜æ¨¡å‹")
                    patience_counter += 1
            else:
                patience_counter += 1
            
            if save_model:
                # ğŸ”¥ ä¿å­˜åˆ°å¯¹æ¯”å­¦ä¹ ä¸“ç”¨è·¯å¾„
                model_filename = f"contrastive_image_encoder_ch{base_channels}.pth"
                best_model_path = os.path.join(self.save_dir, model_filename)
                
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_acc': val_acc,
                    'val_loss': val_loss,
                    'train_acc': train_acc,
                    'train_loss': train_loss,
                    'acc_diff': acc_diff,
                    'base_channels': base_channels,
                    'feature_dim': 512,
                    'architecture': 'ImprovedResNetCBAM3D_SmartDownsample',
                    'config': {  # ğŸ”¥ æ·»åŠ configå­—æ®µä¾›ImprovedImageEncoderè¯»å–
                        'base_channels': base_channels,
                        'feature_dim': 512,
                        'use_global_pool': False,
                        'dropout_rate': 0.3,
                        'in_channels': 3,
                        'num_classes': 2
                    },
                    'training_config': {
                        'num_epochs': num_epochs,
                        'batch_size': batch_size,
                        'learning_rate': learning_rate,
                        'use_global_pool': False,
                        'weight_decay': 5e-4,
                        'patient_level_split': True
                    }
                }, best_model_path)
                
                print(f"  âœ… æ–°çš„æœ€ä½³æ¨¡å‹! éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}% (Epoch {epoch})")
                print(f"     æ¨¡å‹å·²ä¿å­˜: {best_model_path}")
            else:
                print(f"  â³ è€å¿ƒè®¡æ•°: {patience_counter}/{patience}")
            
            # æ—©åœæ£€æŸ¥
            if patience_counter >= patience:
                print(f"\nâ¹ï¸  æ—©åœè§¦å‘! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
                break
            
            # ğŸš¨ å¦‚æœè¿ç»­è¿‡æ‹Ÿåˆå¤ªä¸¥é‡ï¼Œæå‰åœæ­¢
            if consecutive_overfitting >= max_consecutive_overfitting * 2:
                print(f"\nğŸš¨ æ£€æµ‹åˆ°ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œæå‰åœæ­¢è®­ç»ƒ")
                print(f"   å»ºè®®: 1) æ£€æŸ¥æ•°æ®åˆ†å‰²æ˜¯å¦æ­£ç¡® 2) å¢åŠ æ­£åˆ™åŒ– 3) å‡å°‘æ¨¡å‹å¤æ‚åº¦")
                break
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = os.path.join(self.save_dir, f"contrastive_image_encoder_history_ch{base_channels}.json")
        with open(history_path, 'w') as f:
            json.dump(self.train_history, f, indent=2)
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
        print(f"   æœ€ä½³æ¨¡å‹è·¯å¾„: {best_model_path}")
        print(f"   è®­ç»ƒå†å²: {history_path}")
        
        # ğŸ” è®­ç»ƒæ€»ç»“å’Œå»ºè®®
        if best_model_path:
            # åŠ è½½æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹æ¥è·å–è¯¦ç»†ä¿¡æ¯
            checkpoint = torch.load(best_model_path, map_location='cpu')
            final_acc_diff = checkpoint.get('acc_diff', 0)
            
            print(f"\nğŸ“Š è®­ç»ƒæ€»ç»“:")
            print(f"   æœ€ä½³æ¨¡å‹çš„å‡†ç¡®ç‡å·®å¼‚: {final_acc_diff:+.2f}%")
            
            if abs(final_acc_diff) <= 5.0:
                print(f"   âœ… æ¨¡å‹è®­ç»ƒè‰¯å¥½ï¼Œæ— æ˜æ˜¾è¿‡æ‹Ÿåˆ")
            elif final_acc_diff > 5.0:
                print(f"   âš ï¸  å­˜åœ¨è½»å¾®è¿‡æ‹Ÿåˆï¼Œä½†åœ¨å¯æ¥å—èŒƒå›´å†…")
            else:
                print(f"   ğŸ”§ è®­ç»ƒå‡†ç¡®ç‡é«˜äºéªŒè¯å‡†ç¡®ç‡ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ")
            
            print(f"   ğŸ¯ æ¨¡å‹å·²å‡†å¤‡ç”¨äºå¯¹æ¯”å­¦ä¹ ç³»ç»Ÿ!")
        else:
            print(f"   âŒ æœªèƒ½è®­ç»ƒå‡ºæ»¡æ„çš„æ¨¡å‹ï¼Œå»ºè®®è°ƒæ•´è¶…å‚æ•°")
        
        return model, best_val_acc, best_model_path
    
    def save_training_plots(self, base_channels=12):
        """ä¿å­˜è®­ç»ƒæ›²çº¿å›¾"""
        if not self.train_history['epochs']:
            return
        
        plt.figure(figsize=(15, 5))
        
        # æŸå¤±æ›²çº¿
        plt.subplot(1, 3, 1)
        plt.plot(self.train_history['epochs'], self.train_history['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±')
        plt.plot(self.train_history['epochs'], self.train_history['val_loss'], 'r-', label='éªŒè¯æŸå¤±')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
        plt.legend()
        plt.grid(True)
        
        # å‡†ç¡®ç‡æ›²çº¿
        plt.subplot(1, 3, 2)
        plt.plot(self.train_history['epochs'], self.train_history['train_acc'], 'b-', label='è®­ç»ƒå‡†ç¡®ç‡')
        plt.plot(self.train_history['epochs'], self.train_history['val_acc'], 'r-', label='éªŒè¯å‡†ç¡®ç‡')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.title('è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿')
        plt.legend()
        plt.grid(True)
        
        # å­¦ä¹ æ›²çº¿å¯¹æ¯”
        plt.subplot(1, 3, 3)
        plt.plot(self.train_history['epochs'], self.train_history['val_acc'], 'g-', linewidth=2, label='éªŒè¯å‡†ç¡®ç‡')
        plt.axhline(y=max(self.train_history['val_acc']), color='r', linestyle='--', 
                   label=f'æœ€ä½³: {max(self.train_history["val_acc"]):.2f}%')
        plt.xlabel('Epoch')
        plt.ylabel('Validation Accuracy (%)')
        plt.title('éªŒè¯å‡†ç¡®ç‡è¶‹åŠ¿')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plot_path = os.path.join(self.save_dir, f"contrastive_image_encoder_training_ch{base_channels}.png")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {plot_path}")

    def train_single_fold(self, fold_idx, train_images, train_labels, val_images, val_labels,
                         base_channels=12, num_epochs=50, batch_size=4, learning_rate=1e-4, 
                         patience=15, use_cbam=True, **kwargs):
        """
        ğŸ¯ è®­ç»ƒå•ä¸ªäº¤å‰éªŒè¯æŠ˜
        
        Args:
            fold_idx: å½“å‰æŠ˜ç´¢å¼•
            train_images: è®­ç»ƒå›¾åƒæ•°æ®
            train_labels: è®­ç»ƒæ ‡ç­¾
            val_images: éªŒè¯å›¾åƒæ•°æ®  
            val_labels: éªŒè¯æ ‡ç­¾
            base_channels: åŸºç¡€é€šé“æ•°
            num_epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            learning_rate: å­¦ä¹ ç‡
            patience: æ—©åœè€å¿ƒè½®æ•°
            use_cbam: æ˜¯å¦ä½¿ç”¨CBAMæ³¨æ„åŠ›æ¨¡å—
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
            
        Returns:
            dict: è®­ç»ƒç»“æœ
        """
        print(f"\nğŸ¯ å¼€å§‹ç¬¬{fold_idx+1}æŠ˜è®­ç»ƒ...")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(train_labels)}")
        print(f"   éªŒè¯æ ·æœ¬: {len(val_labels)}")
        print(f"   åŸºç¡€é€šé“æ•°: {base_channels}")
        print(f"   è®­ç»ƒè½®æ•°: {num_epochs}")
        print(f"   å­¦ä¹ ç‡: {learning_rate}")
        print(f"   æ—©åœè€å¿ƒ: {patience}")
        
        # é‡ç½®è®­ç»ƒå†å²
        self.train_history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': [],
            'epochs': []
        }
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_contrastive_image_model(
            base_channels=base_channels,
            use_cbam=use_cbam
        )
        
        # å‡†å¤‡æ•°æ®åŠ è½½å™¨
        from torch.utils.data import TensorDataset, DataLoader
        
        # è½¬æ¢ä¸ºå¼ é‡
        train_images_tensor = torch.FloatTensor(train_images)
        train_labels_tensor = torch.LongTensor(train_labels)
        val_images_tensor = torch.FloatTensor(val_images)
        val_labels_tensor = torch.LongTensor(val_labels)
        
        # åˆ›å»ºæ•°æ®é›†å’ŒåŠ è½½å™¨
        train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)
        val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                                num_workers=0, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                              num_workers=0, pin_memory=True)
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = ImprovedFocalLoss(alpha=1.0, gamma=2.0, reduction='mean')
        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=5e-4)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=5, verbose=False, min_lr=1e-6
        )
        
        # è®­ç»ƒè®°å½•
        best_val_acc = 0.0
        patience_counter = 0
        best_epoch = 0
        
        print(f"   å¼€å§‹è®­ç»ƒå¾ªç¯...")
        
        for epoch in range(1, num_epochs + 1):
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_acc = self.train_epoch(model, train_loader, optimizer, criterion, epoch)
            
            # éªŒè¯é˜¶æ®µ
            val_loss, val_acc = self.validate_epoch(model, val_loader, criterion, epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_acc)
            
            # è®°å½•å†å²
            self.train_history['train_loss'].append(train_loss)
            self.train_history['train_acc'].append(train_acc)
            self.train_history['val_loss'].append(val_loss)
            self.train_history['val_acc'].append(val_acc)
            self.train_history['epochs'].append(epoch)
            
            # æ›´æ–°æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_epoch = epoch
                patience_counter = 0
                
                # ä¿å­˜å½“å‰æŠ˜çš„æœ€ä½³æ¨¡å‹
                fold_model_path = os.path.join(self.save_dir, f"fold_{fold_idx}_best_model.pth")
                torch.save({
                    'epoch': epoch,
                    'fold_idx': fold_idx,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_acc': val_acc,
                    'val_loss': val_loss,
                    'train_acc': train_acc,
                    'train_loss': train_loss,
                    'base_channels': base_channels,
                    'feature_dim': 512,
                    'config': {
                        'base_channels': base_channels,
                        'feature_dim': 512,
                        'use_global_pool': False,
                        'dropout_rate': 0.3,
                        'in_channels': 3,
                        'num_classes': 2
                    }
                }, fold_model_path)
                
            else:
                patience_counter += 1
            
            # æ¯10è½®æˆ–æœ€åä¸€è½®æ‰“å°ç»“æœ
            if epoch % 10 == 0 or epoch == num_epochs or patience_counter >= patience:
                print(f"   Epoch {epoch:02d}: Train={train_acc:.2f}%, Val={val_acc:.2f}%, Best={best_val_acc:.2f}%")
            
            # æ—©åœæ£€æŸ¥
            if patience_counter >= patience:
                print(f"   â¹ï¸ æ—©åœè§¦å‘ (è€å¿ƒ={patience}), æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
                break
        
        # ä¿å­˜æ­¤æŠ˜çš„è®­ç»ƒå†å²
        fold_history_path = os.path.join(self.save_dir, f"fold_{fold_idx}_history.json")
        with open(fold_history_path, 'w') as f:
            json.dump(self.train_history, f, indent=2)
        
        print(f"   âœ… ç¬¬{fold_idx+1}æŠ˜å®Œæˆ: æœ€ä½³éªŒè¯å‡†ç¡®ç‡ {best_val_acc:.4f}% (Epoch {best_epoch})")
        
        # è¿”å›ç»“æœ
        return {
            'fold_idx': fold_idx,
            'best_val_accuracy': best_val_acc,
            'best_epoch': best_epoch,
            'final_train_acc': self.train_history['train_acc'][-1] if self.train_history['train_acc'] else 0,
            'final_val_acc': self.train_history['val_acc'][-1] if self.train_history['val_acc'] else 0,
            'total_epochs': len(self.train_history['epochs']),
            'fold_model_path': os.path.join(self.save_dir, f"fold_{fold_idx}_best_model.pth"),
            'fold_history_path': fold_history_path,
            'converged': patience_counter < patience
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ å¯¹æ¯”å­¦ä¹ å›¾åƒç¼–ç å™¨é¢„è®­ç»ƒè„šæœ¬")
    print("=" * 60)
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        device = 'cuda'
        gpu_name = torch.cuda.get_device_name()
        gpu_memory = torch.cuda.get_device_properties(0).total_memory // 1024**3
        print(f"ğŸš€ GPU: {gpu_name} ({gpu_memory}GB)")
    else:
        device = 'cpu'
        print("âš ï¸  ä½¿ç”¨CPUè®­ç»ƒ")
    
    # è·å–æ•°æ®è·¯å¾„
    data_path = get_default_data_path()
    print(f"ğŸ“ æ•°æ®è·¯å¾„: {data_path}")
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®è·¯å¾„æˆ–è¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬")
        return
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ContrastiveImageEncoderTrainer(device=device)
    
    # è®­ç»ƒé…ç½®é€‰æ‹©
    print(f"\nâš™ï¸ é€‰æ‹©è®­ç»ƒé…ç½®:")
    print("1. ğŸ”¥ é«˜æ€§èƒ½é…ç½® (32GB+ GPU)")
    print("2. ğŸ’¾ æ ‡å‡†é…ç½® (16GB+ GPU)")
    print("3. ğŸ”§ å†…å­˜ä¼˜åŒ–é…ç½® (<16GB GPU)")
    print("4. ğŸ§ª å¿«é€Ÿæµ‹è¯•é…ç½® (è°ƒè¯•ç”¨)")
    
    choice = input("è¯·é€‰æ‹©é…ç½® (1-4): ").strip()
    
    if choice == "1":
        print("\nğŸ”¥ é«˜æ€§èƒ½é…ç½®")
        model, best_acc, model_path = trainer.train(
            data_path=data_path,
            base_channels=12,
            num_epochs=60,
            batch_size=8,
            learning_rate=1e-4,
            max_samples=None,
            patience=20
        )
        
    elif choice == "2":
        print("\nğŸ’¾ æ ‡å‡†é…ç½®")
        model, best_acc, model_path = trainer.train(
            data_path=data_path,
            base_channels=12,
            num_epochs=50,
            batch_size=4,
            learning_rate=1e-4,
            max_samples=None,
            patience=15
        )
        
    elif choice == "3":
        print("\nğŸ”§ å†…å­˜ä¼˜åŒ–é…ç½®")
        model, best_acc, model_path = trainer.train(
            data_path=data_path,
            base_channels=8,
            num_epochs=40,
            batch_size=2,
            learning_rate=1e-4,
            max_samples=None,
            patience=15
        )
        
    elif choice == "4":
        print("\nğŸ§ª å¿«é€Ÿæµ‹è¯•é…ç½®")
        model, best_acc, model_path = trainer.train(
            data_path=data_path,
            base_channels=8,
            num_epochs=10,
            batch_size=4,
            learning_rate=1e-4,
            max_samples=50,  # é™åˆ¶æ ·æœ¬æ•°
            patience=5
        )
        
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ ‡å‡†é…ç½®")
        model, best_acc, model_path = trainer.train(
            data_path=data_path,
            base_channels=12,
            num_epochs=50,
            batch_size=4,
            learning_rate=1e-4,
            max_samples=None,
            patience=15
        )
    
    # ä¿å­˜è®­ç»ƒæ›²çº¿
    base_channels = 12 if choice in ["1", "2"] else 8
    trainer.save_training_plots(base_channels)
    
    # æ€»ç»“
    print(f"\n" + "=" * 60)
    print("ğŸ‰ å¯¹æ¯”å­¦ä¹ å›¾åƒç¼–ç å™¨é¢„è®­ç»ƒå®Œæˆ")
    print("=" * 60)
    print(f"ğŸ¯ æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜è·¯å¾„: {model_path}")
    print(f"ğŸ“ ä¿å­˜ç›®å½•: {trainer.save_dir}")
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print(f"\nğŸ“ åç»­æ­¥éª¤:")
    print("1. ğŸ”— ä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ è®­ç»ƒ")
    print("2. ğŸ“Š åœ¨å¯¹æ¯”å­¦ä¹ ä¸­åŠ è½½æ­¤é¢„è®­ç»ƒæƒé‡")
    print("3. ğŸ¯ æœŸå¾…å¤šæ¨¡æ€èåˆæ€§èƒ½æå‡")
    
    print(f"\nğŸš€ å¯åŠ¨å¯¹æ¯”å­¦ä¹ è®­ç»ƒ:")
    print(f"python run_contrastive_training.py")

if __name__ == "__main__":
    main() 