import onnxruntime as ort
import os

def inspect_onnx_model(model_path):
    """
    åŠ è½½ä¸€ä¸ªONNXæ¨¡å‹å¹¶æ‰“å°å…¶è¾“å…¥å’Œè¾“å‡ºèŠ‚ç‚¹çš„åç§°ã€å½¢çŠ¶ã€‚
    """
    print(f"ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨æ£€æŸ¥æ¨¡å‹: {model_path}")

    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°äº '{model_path}'")
        print("   è¯·ç¡®ä¿æ‚¨å·²ç»æˆåŠŸè¿è¡Œ 'export_model.py' å¹¶ä¸”è¯¥æ–‡ä»¶ä½äºé¡¹ç›®æ ¹ç›®å½•ã€‚")
        return

    try:
        # åˆ›å»ºä¸€ä¸ªæ¨ç†ä¼šè¯
        session = ort.InferenceSession(model_path)

        # è·å–è¾“å…¥ä¿¡æ¯
        print("\n--- æ¨¡å‹çš„è¾“å…¥ (Inputs) ---")
        inputs = session.get_inputs()
        for i, input_node in enumerate(inputs):
            print(f"  [{i}] åç§° (Name): {input_node.name}")
            print(f"      å½¢çŠ¶ (Shape): {input_node.shape}")
            print(f"      ç±»å‹ (Type): {input_node.type}")

        # è·å–è¾“å‡ºä¿¡æ¯
        print("\n--- æ¨¡å‹çš„è¾“å‡º (Outputs) ---")
        outputs = session.get_outputs()
        for i, output_node in enumerate(outputs):
            print(f"  [{i}] åç§° (Name): {output_node.name}")
            print(f"      å½¢çŠ¶ (Shape): {output_node.shape}")
            print(f"      ç±»å‹ (Type): {output_node.type}")

        print("\nâœ… æ£€æŸ¥å®Œæˆã€‚")
        print("ğŸ‘‰ è¯·å°†ä¸Šé¢åˆ—å‡ºçš„ 'è¾“å‡º (Outputs)' åç§°æ›´æ–°åˆ° 'frontend/script.js' æ–‡ä»¶ä¸­ã€‚")

    except Exception as e:
        print(f"\nâŒ åŠ è½½æˆ–æ£€æŸ¥æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    # æˆ‘ä»¬è¦æ£€æŸ¥çš„æ¨¡å‹æ–‡ä»¶ï¼Œå®ƒåº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•
    onnx_file_path = "mci_classifier.onnx"
    inspect_onnx_model(onnx_file_path) 