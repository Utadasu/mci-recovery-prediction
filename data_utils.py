import os
from torch.utils.data import DataLoader, Subset, ConcatDataset
from dataset import SimpleDataset
import random
import numpy as np
import nibabel as nib
from scipy.ndimage import rotate
import torch
from torch.utils.data import Dataset
from torchvision import transforms
import logging
from typing import List, Tuple, Dict, Optional, Union
import torch.nn.functional as F
from scipy.ndimage import gaussian_filter, map_coordinates
import pandas as pd
import re
from tqdm import tqdm # Added for progress bar

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def get_default_data_path():
    """
    æ™ºèƒ½è·å–é»˜è®¤æ•°æ®è·¯å¾„ï¼Œå…¼å®¹æœåŠ¡å™¨å’Œæœ¬åœ°ç¯å¢ƒã€‚
    éµå¾ªMCI_DATAæ•°æ®è§„èŒƒï¼Œä½¿ç”¨æ­£ç¡®çš„æ ¹ç›®å½•è·¯å¾„ã€‚
    """
    # ä¼˜å…ˆæ£€æŸ¥æœåŠ¡å™¨è·¯å¾„ - éµå¾ªMCI_DATAè§„èŒƒ
    server_paths = [
        "/root/autodl-tmp/MCI_DATA/", # V3.5 æ›´æ–°: æŒ‡å‘è§„èŒƒçš„MCI_DATAæ ¹ç›®å½•
        "/root/autodl-tmp/DATA_MCI/", # å…¼å®¹æ—§è·¯å¾„
        "/autodl-fs/data/ZM_Files/å¤‡ä»½5.27/test_data/",
        "/autodl-fs/data/test_data/"
    ]
    for path in server_paths:
        if os.path.exists(path):
            logger.info(f"æ£€æµ‹åˆ°æœåŠ¡å™¨æ•°æ®è·¯å¾„: {path}")
            return path
    
    # æ£€æŸ¥æœ¬åœ°è°ƒè¯•è·¯å¾„
    local_paths = [
        "./test_data/",
        "../test_data/",
        "../../test_data/"
    ]
    for path in local_paths:
        if os.path.exists(os.path.abspath(path)):
            abs_path = os.path.abspath(path)
            logger.info(f"æ£€æµ‹åˆ°æœ¬åœ°æ•°æ®è·¯å¾„: {abs_path}")
            return abs_path
            
    logger.warning("æœªæ‰¾åˆ°ä»»ä½•é¢„è®¾çš„æ•°æ®è·¯å¾„ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šã€‚å°†è¿”å›ç¬¬ä¸€ä¸ªæœåŠ¡å™¨è·¯å¾„ä½œä¸ºé»˜è®¤å€¼ã€‚")
    return server_paths[0]

def create_tissue_specific_dataset(data_path, tissue_type):
    """Create dataset for specific tissue type"""
    # Create a copy of data_path with modified paths
    tissue_data_path = data_path.copy()
    
    # ç›´æ¥æ„å»ºåˆ°å…·ä½“å­ç›®å½•çš„è·¯å¾„
    if tissue_type == 'CSF':
        tissue_data_path['ad_dir'] = os.path.join(data_path['ad_dir'], 'ADfinalCSF')
        tissue_data_path['cn_dir'] = os.path.join(data_path['cn_dir'], 'CNfinalCSF')
    elif tissue_type == 'GRAY':
        tissue_data_path['ad_dir'] = os.path.join(data_path['ad_dir'], 'ADfinalGRAY')
        tissue_data_path['cn_dir'] = os.path.join(data_path['cn_dir'], 'CNfinalGRAY')
    elif tissue_type == 'WHITE':
        tissue_data_path['ad_dir'] = os.path.join(data_path['ad_dir'], 'ADfinalWHITE')
        tissue_data_path['cn_dir'] = os.path.join(data_path['cn_dir'], 'CNfinalWHITE')
    else:
        raise ValueError(f"Unknown tissue type: {tissue_type}")
    
    # Verify paths exist
    print(f"\nVerifying paths for {tissue_type}:")
    print(f"AD path: {tissue_data_path['ad_dir']}")
    print(f"CN path: {tissue_data_path['cn_dir']}")
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(tissue_data_path['ad_dir']):
        # å°è¯•åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾
        if os.path.exists(data_path['ad_dir']):
            print(f"AD directory {tissue_data_path['ad_dir']} does not exist.")
            print(f"Available AD directories:")
            for item in os.listdir(data_path['ad_dir']):
                print(f"  - {item}")
        raise ValueError(f"AD directory does not exist: {tissue_data_path['ad_dir']}")
    
    if not os.path.exists(tissue_data_path['cn_dir']):
        # å°è¯•åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾
        if os.path.exists(data_path['cn_dir']):
            print(f"CN directory {tissue_data_path['cn_dir']} does not exist.")
            print(f"Available CN directories:")
            for item in os.listdir(data_path['cn_dir']):
                print(f"  - {item}")
        raise ValueError(f"CN directory does not exist: {tissue_data_path['cn_dir']}")
    
    # åªæ‰“å°ç›®å½•å­˜åœ¨ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºå…·ä½“å†…å®¹
    print(f"\nADç›®å½•åŒ…å«æ–‡ä»¶æ•°: {len([f for f in os.listdir(tissue_data_path['ad_dir']) if f.endswith('.nii')])}")
    print(f"CNç›®å½•åŒ…å«æ–‡ä»¶æ•°: {len([f for f in os.listdir(tissue_data_path['cn_dir']) if f.endswith('.nii')])}")
    
    return SimpleDataset(tissue_data_path)

def create_data_loaders(dataset, batch_size=32, num_workers=8):
    """Create train and validation data loaders with patient-wise split"""
    # è·å–æ‰€æœ‰å”¯ä¸€çš„æ‚£è€…ID
    patient_ids = list(set(dataset.patient_ids))
    random.shuffle(patient_ids)
    
    # æŒ‰æ‚£è€…IDåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    split_idx = int(len(patient_ids) * 0.8)
    train_patients = patient_ids[:split_idx]
    val_patients = patient_ids[split_idx:]
    
    # åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç´¢å¼•
    train_indices = []
    val_indices = []
    
    for idx, patient_id in enumerate(dataset.patient_ids):
        if patient_id in train_patients:
            train_indices.append(idx)
        else:
            val_indices.append(idx)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = Subset(dataset, train_indices)
    val_dataset = Subset(dataset, val_indices)
    
    print(f"\næ•°æ®é›†åˆ’åˆ†ä¿¡æ¯:")
    print(f"è®­ç»ƒé›†æ‚£è€…æ•°: {len(train_patients)}")
    print(f"éªŒè¯é›†æ‚£è€…æ•°: {len(val_patients)}")
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_indices)}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_indices)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, val_loader

# æ•°æ®å¢å¼ºè½¬æ¢
class RandomRotation3D:
    def __init__(self, degrees=10):
        self.degrees = degrees

    def __call__(self, x):
        angle = random.uniform(-self.degrees, self.degrees)
        return F.rotate(x, angle, mode='bilinear')

class RandomFlip3D:
    def __init__(self, p=0.5):
        self.p = p

    def __call__(self, x):
        if random.random() < self.p:
            x = torch.flip(x, [2])  # æ°´å¹³ç¿»è½¬
        if random.random() < self.p:
            x = torch.flip(x, [3])  # å‚ç›´ç¿»è½¬
        return x

class RandomBrightnessContrast:
    def __init__(self, brightness=0.2, contrast=0.2):
        self.brightness = brightness
        self.contrast = contrast

    def __call__(self, x):
        brightness_factor = 1.0 + random.uniform(-self.brightness, self.brightness)
        contrast_factor = 1.0 + random.uniform(-self.contrast, self.contrast)
        x = x * brightness_factor
        x = (x - x.mean()) * contrast_factor + x.mean()
        return x

class GammaCorrection:
    def __init__(self, gamma_range=(0.8, 1.2)):
        self.gamma_range = gamma_range

    def __call__(self, x):
        gamma = random.uniform(*self.gamma_range)
        x = torch.pow(x, gamma)
        return x

# å¢å¼ºå‹æ•°æ®å¢å¼ºæ–¹æ³•
class ElasticDeformation:
    """å¼¹æ€§å˜å½¢å¢å¼ºæ–¹æ³•ï¼Œå¯¹3DåŒ»å­¦å›¾åƒç‰¹åˆ«æœ‰æ•ˆ"""
    def __init__(self, alpha=1, sigma=0.1, apply_prob=0.3):
        self.alpha = alpha
        self.sigma = sigma
        self.apply_prob = apply_prob
        
    def __call__(self, img):
        if random.random() > self.apply_prob:
            return img
            
        # ç¡®ä¿æˆ‘ä»¬æ­£ç¡®å¤„ç†åŒ…å«é€šé“ç»´åº¦çš„å›¾åƒå½¢çŠ¶
        # imgçš„å½¢çŠ¶åº”è¯¥æ˜¯ (C, D, H, W) æˆ– (D, H, W)
        input_shape = img.shape
        
        # åˆ¤æ–­è¾“å…¥æ˜¯3Dè¿˜æ˜¯4Dï¼ˆå¸¦é€šé“ï¼‰
        has_channel_dim = len(input_shape) == 4
        
        if has_channel_dim:
            # å¦‚æœæœ‰é€šé“ç»´åº¦ï¼Œæˆ‘ä»¬å°†å…¶åˆ†ç¦»å‡ºæ¥å•ç‹¬å¤„ç†
            C, D, H, W = input_shape
            img_no_channel = img[0]  # å‡è®¾åªæœ‰ä¸€ä¸ªé€šé“
        else:
            # ç›´æ¥ä½¿ç”¨3Dä½“æ•°æ®
            D, H, W = input_shape
            img_no_channel = img
            
        # ä¸º3Då›¾åƒåˆ›å»ºå½¢å˜çŸ¢é‡åœº
        shape = (D, H, W)
        
        # åˆ›å»ºéšæœºä½ç§»åœºå¹¶ä½¿ç”¨é«˜æ–¯æ»¤æ³¢å¹³æ»‘å®ƒä»¬
        dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), self.sigma) * self.alpha
        dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), self.sigma) * self.alpha
        dz = gaussian_filter((np.random.rand(*shape) * 2 - 1), self.sigma) * self.alpha
        
        # åˆ›å»ºç½‘æ ¼åæ ‡
        z, y, x = np.meshgrid(np.arange(D), np.arange(H), np.arange(W), indexing='ij')
        
        # åº”ç”¨ä½ç§»åœºï¼Œå¹¶æ‰å¹³åŒ–åæ ‡ä»¥ç”¨äºmap_coordinates
        indices = [
            np.reshape(z + dz, (-1,)), 
            np.reshape(y + dy, (-1,)), 
            np.reshape(x + dx, (-1,))
        ]
        
        # åº”ç”¨å½¢å˜
        distorted_img = map_coordinates(img_no_channel, indices, order=1, mode='reflect')
        
        # æ¢å¤åŸå§‹å½¢çŠ¶
        distorted_img = distorted_img.reshape(shape)
        
        # å¦‚æœåŸå§‹è¾“å…¥æœ‰é€šé“ç»´åº¦ï¼Œåˆ™æ·»åŠ å›å»
        if has_channel_dim:
            distorted_img = distorted_img[np.newaxis, ...]
            
        return distorted_img

class RandomIntensityShift:
    """éšæœºå¼ºåº¦åç§»å¢å¼º"""
    def __init__(self, shift_range=0.1, apply_prob=0.3):
        self.shift_range = shift_range
        self.apply_prob = apply_prob
        
    def __call__(self, img):
        if random.random() > self.apply_prob:
            return img
            
        shift = random.uniform(-self.shift_range, self.shift_range)
        return img + shift

class RandomIntensityScale:
    """éšæœºå¼ºåº¦ç¼©æ”¾å¢å¼º"""
    def __init__(self, scale_range=(0.9, 1.1), apply_prob=0.3):
        self.scale_range = scale_range
        self.apply_prob = apply_prob
        
    def __call__(self, img):
        if random.random() > self.apply_prob:
            return img
            
        scale = random.uniform(self.scale_range[0], self.scale_range[1])
        return img * scale

# æ•°æ®é›†ç±»
class SimpleDataset(Dataset):
    def __init__(self, data_path):
        self.data_path = data_path
        self.samples = []  # æ–‡ä»¶è·¯å¾„
        self.labels = []   # æ ‡ç­¾ï¼ˆAD=0ï¼ŒCN=1ï¼‰
        self.patient_ids = []  # æ‚£è€…ID
        self.modality_info = []  # æ¨¡æ€ä¿¡æ¯
        
        # ç”¨äºç»Ÿè®¡æ‚£è€…IDä¿¡æ¯
        self.patient_stats = {
            'ad': {'total': 0, 'ids': set()},
            'cn': {'total': 0, 'ids': set()}
        }
        
        # ç¡®å®šå½“å‰æ•°æ®é›†çš„æ¨¡æ€ç±»å‹
        ad_dir = data_path['ad_dir']
        if 'CSF' in ad_dir:
            self.modality = 'CSF'
        elif 'GRAY' in ad_dir:
            self.modality = 'GRAY'
        elif 'WHITE' in ad_dir:
            self.modality = 'WHITE'
        else:
            self.modality = 'UNKNOWN'
        
        print(f"\nåŠ è½½ {self.modality} æ¨¡æ€æ•°æ®:")
        print(f"ADç›®å½•: {data_path['ad_dir']}")
        print(f"CNç›®å½•: {data_path['cn_dir']}")
        print(f"ADç›®å½•å­˜åœ¨: {os.path.exists(data_path['ad_dir'])}")
        print(f"CNç›®å½•å­˜åœ¨: {os.path.exists(data_path['cn_dir'])}")
        
        # å¤„ç†ADæ•°æ®ï¼ˆæ ‡ç­¾0ï¼‰
        ad_dir = data_path['ad_dir']
        if os.path.exists(ad_dir):
            print(f"\nå¤„ç†AD {self.modality}å›¾åƒæ–‡ä»¶:")
            file_count = 0
            for img_name in os.listdir(ad_dir):
                if img_name.endswith('.nii'):
                    file_count += 1
                    # æå–æ‚£è€…IDï¼Œè§„èŒƒåŒ–ä¸ºä¸€è‡´çš„IDæ ¼å¼
                    patient_id = self._extract_patient_id(img_name)
                    
                    self.patient_stats['ad']['total'] += 1
                    self.samples.append(os.path.join(ad_dir, img_name))
                    self.labels.append(0)  # ADæ ‡ç­¾ä¸º0
                    self.patient_ids.append(patient_id)
                    self.modality_info.append(self.modality)
                    self.patient_stats['ad']['ids'].add(patient_id)
        
        # å¤„ç†CNæ•°æ®ï¼ˆæ ‡ç­¾1ï¼‰
        cn_dir = data_path['cn_dir']
        if os.path.exists(cn_dir):
            print(f"\nå¤„ç†CN {self.modality}å›¾åƒæ–‡ä»¶:")
            file_count = 0
            for img_name in os.listdir(cn_dir):
                if img_name.endswith('.nii'):
                    file_count += 1
                    # æå–æ‚£è€…IDï¼Œè§„èŒƒåŒ–ä¸ºä¸€è‡´çš„IDæ ¼å¼
                    patient_id = self._extract_patient_id(img_name)
                    
                    self.patient_stats['cn']['total'] += 1
                    self.samples.append(os.path.join(cn_dir, img_name))
                    self.labels.append(1)  # CNæ ‡ç­¾ä¸º1
                    self.patient_ids.append(patient_id)
                    self.modality_info.append(self.modality)
                    self.patient_stats['cn']['ids'].add(patient_id)
        
        # æ‰“å°æ‚£è€…IDç»Ÿè®¡ä¿¡æ¯
        print(f"\n{self.modality}æ¨¡æ€æ‚£è€…IDç»Ÿè®¡ä¿¡æ¯:")
        print("ADæ‚£è€…:")
        print(f"  å”¯ä¸€æ‚£è€…æ€»æ•°: {len(self.patient_stats['ad']['ids'])}")
        print(f"  æ€»å›¾åƒæ•°: {self.patient_stats['ad']['total']}")
        print("CNæ‚£è€…:")
        print(f"  å”¯ä¸€æ‚£è€…æ€»æ•°: {len(self.patient_stats['cn']['ids'])}")
        print(f"  æ€»å›¾åƒæ•°: {self.patient_stats['cn']['total']}")
        
        print(f"\n{self.modality}æ¨¡æ€åŠ è½½çš„æ€»æ ·æœ¬æ•°: {len(self.samples)}")
        if len(self.samples) == 0:
            raise ValueError(f"æœªæ‰¾åˆ°{self.modality}æ¨¡æ€çš„æœ‰æ•ˆæ ·æœ¬ï¼è¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ–‡ä»¶å‘½åæ ¼å¼ã€‚")
    
    def _extract_patient_id(self, filename):
        """ä»æ–‡ä»¶åä¸­æå–è§„èŒƒåŒ–çš„æ‚£è€…ID - ä¿®å¤NAMEåˆ—å¯¹é½"""
        # ç§»é™¤åç¼€
        basename = filename.split('.')[0]
        
        # é’ˆå¯¹ADNIæ•°æ®æ ¼å¼: "029_S_4385_3-2016-01-29_12_25_03.0.nii"æˆ–"mwp1MRI_002_S_0295_2006-04-18_08_51_20.0.nii"
        # æå–NAMEéƒ¨åˆ†: "029_S_4385"æˆ–"002_S_0295"
        if '_' in basename:
            parts = basename.split('_')
            # å¯»æ‰¾æ ¼å¼ä¸º "æ•°å­—_S_æ•°å­—" çš„éƒ¨åˆ†
            for i in range(len(parts) - 2):
                if parts[i+1] == 'S' and parts[i].isdigit() and parts[i+2].isdigit():
                    return f"{parts[i]}_{parts[i+1]}_{parts[i+2]}"
            
            # é’ˆå¯¹mwp*MRIæ ¼å¼: "mwp1MRI_002_S_0295_2006-04-18_08_51_20.0"
            if len(parts) >= 4 and parts[1] == 'S':
                return f"{parts[0]}_{parts[1]}_{parts[2]}"
            
            # é€šç”¨æ ¼å¼ï¼šå–å‰3ä¸ªéƒ¨åˆ†
            elif len(parts) >= 3:
                return f"{parts[0]}_{parts[1]}_{parts[2]}"
            else:
                return basename  # å¦‚æœä¸ç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œä½¿ç”¨å…¨å
        
        # å¦‚æœæ²¡æœ‰ä¸‹åˆ’çº¿ï¼Œåªä¿ç•™æ•°å­—ä½œä¸ºID
        numeric_id = re.sub(r'[^0-9]', '', basename)
        if numeric_id:
            return numeric_id
        
        # æœ€åçš„å¤‡é€‰æ˜¯æ•´ä¸ªæ–‡ä»¶åï¼ˆä¸å«åç¼€ï¼‰
        return basename
    
    def __len__(self):
        return len(self.samples)
    
    # ç§»é™¤resize_3dæ–¹æ³•ï¼Œä¿æŒå›¾åƒåŸå§‹å°ºå¯¸
    
    def normalize_image(self, img):
        """ç®€å•çš„å›¾åƒå½’ä¸€åŒ–"""
        if img.max() > img.min():
            img = (img - img.mean()) / img.std()  # Z-scoreå½’ä¸€åŒ–
        return img
    
    def random_gamma(self, img, gamma_range=(0.8, 1.2)):
        """éšæœºä¼½é©¬æ ¡æ­£"""
        gamma = np.random.uniform(gamma_range[0], gamma_range[1])
        # å¤„ç†è´Ÿå€¼ï¼šä¿ç•™ç¬¦å·ï¼Œå¯¹ç»å¯¹å€¼åº”ç”¨ä¼½é©¬
        img_signed = np.sign(img)  # è·å–ç¬¦å· (-1, 0, 1)
        img_abs = np.abs(img) + 1e-8  # è·å–ç»å¯¹å€¼å¹¶æ·»åŠ åç§»
        return img_signed * np.power(img_abs, gamma)  # ä¿ç•™åŸå§‹ç¬¦å·
    
    def __getitem__(self, idx):
        try:
            # åŠ è½½å›¾åƒ
            img = nib.load(self.samples[idx]).get_fdata()
            
            # æ•°æ®å¢å¼º
            if random.random() > 0.5:
                # éšæœºæ—‹è½¬
                angle = random.uniform(-10, 10)
                img = rotate(img, angle, axes=(0, 1), reshape=False)
            
            if random.random() > 0.5:
                # éšæœºç¿»è½¬
                img = np.flip(img, axis=0)
            
            if random.random() > 0.5:
                # éšæœºç¿»è½¬
                img = np.flip(img, axis=1)
                
            # åŸºç¡€æ•°æ®å¢å¼º
            if random.random() > 0.5:
                # éšæœºäº®åº¦
                brightness_factor = random.uniform(0.8, 1.2)
                img = img * brightness_factor
            
            # æ¨¡æ€ç‰¹å®šå¢å¼º
            if self.modality in ['GRAY', 'WHITE']:
                if random.random() > 0.5:
                    # å¢å¼ºå¯¹æ¯”åº¦ï¼Œæ‰©å¤§å‚æ•°èŒƒå›´ä»¥æ›´å¥½åœ°å¢å¼ºè¿™äº›æ¨¡æ€çš„ç‰¹å¾
                    contrast_factor = random.uniform(0.75, 1.25)  # å¯¹æ¯”åº¦èŒƒå›´æ‰©å¤§
                    mean = np.mean(img)
                    img = (img - mean) * contrast_factor + mean
                    
                if random.random() > 0.7:  # ä¸ºè¿™äº›æ¨¡æ€é¢å¤–åº”ç”¨é”åŒ–
                    # ç®€å•çš„é”åŒ–æ“ä½œ - æ‹‰æ™®æ‹‰æ–¯é”åŒ–
                    from scipy.ndimage import laplace
                    edge = laplace(img)
                    img = img - 0.2 * edge  # å¼±é”åŒ–ï¼Œé¿å…è¿‡åº¦å¼ºåŒ–å™ªå£°
            elif self.modality == 'CSF':
                # ä¸ºCSFä½¿ç”¨æ­£å¸¸å¯¹æ¯”åº¦å‚æ•°
                if random.random() > 0.5:
                    contrast_factor = random.uniform(0.8, 1.2)
                    mean = np.mean(img)
                    img = (img - mean) * contrast_factor + mean
            
            # å½’ä¸€åŒ–
            img = self.normalize_image(img)
            
            # æ·»åŠ é€šé“ç»´åº¦
            img = img[np.newaxis, ...]
            
            # åº”ç”¨é«˜çº§å¢å¼º
            if random.random() > 0.5:
                if random.random() > 0.7:  # 30%æ¦‚ç‡åº”ç”¨å¼¹æ€§å˜å½¢
                    elastic_transform = ElasticDeformation(alpha=1, sigma=0.1)
                    img = elastic_transform(img)
                
                if random.random() > 0.7:  # 30%æ¦‚ç‡åº”ç”¨å¼ºåº¦åç§»
                    intensity_shift = RandomIntensityShift(shift_range=0.1)
                    img = intensity_shift(img)
                    
                if random.random() > 0.7:  # 30%æ¦‚ç‡åº”ç”¨å¼ºåº¦ç¼©æ”¾
                    intensity_scale = RandomIntensityScale(scale_range=(0.9, 1.1))
                    img = intensity_scale(img)
            
            return torch.FloatTensor(img), self.labels[idx], self.patient_ids[idx], self.modality_info[idx]
        except Exception as e:
            print(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {str(e)}")
            print(f"å›¾åƒè·¯å¾„: {self.samples[idx]}")
            raise 

@staticmethod
def load_early_fusion_data(data_dir: str, max_samples: int = None):
        """
        åŠ è½½ç”¨äºæ—©æœŸèåˆçš„ä¸‰æ¨¡æ€MRIæ•°æ® (CSF, GREY, WHITE)ã€‚
        V3.5 æ›´æ–°: é€‚é…æ–°çš„ totalAD/totalCN ç›®å½•ç»“æ„ã€‚
    
        Args:
            data_dir: åŒ…å« totalAD å’Œ totalCN å­ç›®å½•çš„æ•°æ®æ ¹ç›®å½•ã€‚
            max_samples: æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰ã€‚
    
        Returns:
            Tuple[np.ndarray, np.ndarray]: (images, labels)
        """
        logger.info(f"å¼€å§‹ä» {data_dir} åŠ è½½æ—©æœŸèåˆæ•°æ® (æ–°ç»“æ„)...")
        
        # å®šä¹‰ADå’ŒCNçš„æ•°æ®ç›®å½•
        ad_dir = os.path.join(data_dir, 'totalAD')
        cn_dir = os.path.join(data_dir, 'totalCN')
        
        if not os.path.exists(ad_dir) or not os.path.exists(cn_dir):
            raise FileNotFoundError(f"åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ° totalAD æˆ– totalCN ç›®å½•ã€‚")
    
        def extract_patient_id_from_filename(filename):
            # åŒ¹é… mwp1MRI_002_S_0295_2006-04-18_08_51_20.0.nii æ ¼å¼
            match = re.search(r'mwp\dMRI_(\d{3}_S_\d{4})_', filename)
            if match:
                return match.group(1)
            logger.warning(f"æ— æ³•ä»æ–‡ä»¶å {filename} æå–æ ‡å‡†æ‚£è€…IDã€‚")
            return None
    
        def load_nii_files_with_patient_id(directory):
            patient_files = {}
            if not os.path.exists(directory):
                logger.warning(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
                return {}
            for filename in os.listdir(directory):
                if filename.endswith((".nii", ".nii.gz")):
                    patient_id = extract_patient_id_from_filename(filename)
                    if patient_id:
                        patient_files[patient_id] = os.path.join(directory, filename)
            return patient_files
    
        # åŠ è½½æ¯ä¸ªæ¨¡æ€çš„æ–‡ä»¶è·¯å¾„ - éµå¾ªMCI_DATAè§„èŒƒ
        ad_csf_files = load_nii_files_with_patient_id(os.path.join(ad_dir, 'ADfinalCSF'))
        ad_gray_files = load_nii_files_with_patient_id(os.path.join(ad_dir, 'ADfinalGRAY'))
        ad_white_files = load_nii_files_with_patient_id(os.path.join(ad_dir, 'ADfinalWHITE'))

        cn_csf_files = load_nii_files_with_patient_id(os.path.join(cn_dir, 'CNfinalCSF'))
        cn_gray_files = load_nii_files_with_patient_id(os.path.join(cn_dir, 'CNfinalGRAY'))
        cn_white_files = load_nii_files_with_patient_id(os.path.join(cn_dir, 'CNfinalWHITE'))
        
        logger.info(f"AD æ¨¡æ€æ–‡ä»¶æ•°é‡: CSF={len(ad_csf_files)}, GRAY={len(ad_gray_files)}, WHITE={len(ad_white_files)}")
        logger.info(f"CN æ¨¡æ€æ–‡ä»¶æ•°é‡: CSF={len(cn_csf_files)}, GRAY={len(cn_gray_files)}, WHITE={len(cn_white_files)}")
    
        all_images = []
        all_labels = []
    
        # å¤„ç†ADæ•°æ®
        ad_patient_ids = set(ad_csf_files.keys()) & set(ad_gray_files.keys()) & set(ad_white_files.keys())
        logger.info(f"æ‰¾åˆ° {len(ad_patient_ids)} ä¸ªä¸‰æ¨¡æ€å®Œæ•´çš„ADæ‚£è€…ã€‚")
        
        if max_samples is not None:
            ad_patient_ids = list(ad_patient_ids)[:max_samples]
    
        for patient_id in tqdm(ad_patient_ids, desc="å¤„ç† AD æ•°æ®"):
            try:
                csf_img = nib.load(ad_csf_files[patient_id]).get_fdata().astype(np.float32)
                gray_img = nib.load(ad_gray_files[patient_id]).get_fdata().astype(np.float32)
                white_img = nib.load(ad_white_files[patient_id]).get_fdata().astype(np.float32)

                if csf_img.shape == gray_img.shape == white_img.shape:
                    stacked_img = np.stack([csf_img, gray_img, white_img], axis=0)
                    all_images.append(stacked_img)
                    all_labels.append(1)
                else:
                    logger.warning(f"æ‚£è€… {patient_id} (AD) çš„æ¨¡æ€å½¢çŠ¶ä¸åŒ¹é…ï¼Œå·²è·³è¿‡ã€‚")
            except Exception as e:
                logger.error(f"å¤„ç†æ‚£è€… {patient_id} (AD) æ—¶å‡ºé”™: {e}")
    
        # å¤„ç†CNæ•°æ®
        cn_patient_ids = set(cn_csf_files.keys()) & set(cn_gray_files.keys()) & set(cn_white_files.keys())
        logger.info(f"æ‰¾åˆ° {len(cn_patient_ids)} ä¸ªä¸‰æ¨¡æ€å®Œæ•´çš„CNæ‚£è€…ã€‚")
    
        if max_samples is not None:
            cn_patient_ids = list(cn_patient_ids)[:max_samples]
    
        for patient_id in tqdm(cn_patient_ids, desc="å¤„ç† CN æ•°æ®"):
            try:
                csf_img = nib.load(cn_csf_files[patient_id]).get_fdata().astype(np.float32)
                gray_img = nib.load(cn_gray_files[patient_id]).get_fdata().astype(np.float32)
                white_img = nib.load(cn_white_files[patient_id]).get_fdata().astype(np.float32)

                if csf_img.shape == gray_img.shape == white_img.shape:
                    stacked_img = np.stack([csf_img, gray_img, white_img], axis=0)
                    all_images.append(stacked_img)
                    all_labels.append(0)
                else:
                    logger.warning(f"æ‚£è€… {patient_id} (CN) çš„æ¨¡æ€å½¢çŠ¶ä¸åŒ¹é…ï¼Œå·²è·³è¿‡ã€‚")
            except Exception as e:
                logger.error(f"å¤„ç†æ‚£è€… {patient_id} (CN) æ—¶å‡ºé”™: {e}")
    
        if not all_images:
            logger.error("æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆçš„å›¾åƒæ•°æ®ã€‚")
            return np.array([]), np.array([])
    
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆã€‚æ€»æ ·æœ¬æ•°: {len(all_images)} (AD: {np.sum(all_labels)}, CN: {len(all_labels) - np.sum(all_labels)})")
        
        return np.array(all_images), np.array(all_labels)

def load_text_data_from_excel(text_data_dir: str = "./æ–‡æœ¬ç¼–ç å™¨") -> Tuple[List[str], List[int]]:
    """
    ä»Excelæ–‡ä»¶åŠ è½½æ–‡æœ¬æ•°æ®ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–çš„ä¸´åºŠæ–‡æœ¬ã€‚
    
    æ•°æ®è§„æ¨¡:
    - ADæ‚£è€…: 414ä¸ªæ ·æœ¬ (final_AD_updated.xlsx, 24KB)
    - CNå¯¹ç…§: 414ä¸ªæ ·æœ¬ (final_CN_updated.xlsx, 31KB)  
    - æ€»è®¡: 828ä¸ªæ ·æœ¬
    
    æ–‡æœ¬æ¨¡æ¿:
    Age: [XX] years
    Sex: [Male/Female]
    Education: [XX] years
    Neuropsychological Scores:
    Mini-Mental State Examination (MMSE): [XX/30]
    Clinical Dementia Rating - Sum of Boxes (CDR-SB): [XX]
    Diagnosis: [Alzheimer's Disease (AD)/Cognitively Normal (CN)]
    
    Args:
        text_data_dir: æ–‡æœ¬æ•°æ®ç›®å½•ï¼ŒåŒ…å«final_AD_updated.xlsxå’Œfinal_CN_updated.xlsx
    
    Returns:
        texts: æ–‡æœ¬åˆ—è¡¨ (828ä¸ª)
        labels: æ ‡ç­¾åˆ—è¡¨ (0=CN, 1=AD)
    """
    print("ğŸ“ ä»Excelæ–‡ä»¶åŠ è½½çœŸå®æ–‡æœ¬æ•°æ®...")
    print("ğŸ“Š é¢„æœŸæ•°æ®è§„æ¨¡: AD=414, CN=414, æ€»è®¡=828")
    
    ad_file = os.path.join(text_data_dir, "final_AD_updated.xlsx")
    cn_file = os.path.join(text_data_dir, "final_CN_updated.xlsx")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(ad_file):
        raise FileNotFoundError(f"âŒ ADæ–‡æœ¬æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {ad_file}")
    if not os.path.exists(cn_file):
        raise FileNotFoundError(f"âŒ CNæ–‡æœ¬æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {cn_file}")
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    ad_size = os.path.getsize(ad_file) / 1024  # KB
    cn_size = os.path.getsize(cn_file) / 1024  # KB
    print(f"ğŸ“ æ–‡ä»¶å¤§å°æ£€æŸ¥: AD={ad_size:.1f}KB, CN={cn_size:.1f}KB")
    
    texts = []
    labels = []
    
    def create_clinical_text(row, diagnosis):
        """æ ¹æ®æ•°æ®è¡Œåˆ›å»ºä¸´åºŠæ–‡æœ¬æ¨¡æ¿"""
        # æ€§åˆ«æ˜ å°„
        gender_map = {0: 'Male', 1: 'Female', '0': 'Male', '1': 'Female'}
        gender = gender_map.get(row.get('Gender', 0), 'Unknown')
        
        # è·å–å„é¡¹æ•°æ®ï¼Œå¤„ç†ç¼ºå¤±å€¼
        age = row.get('Age', 'Unknown')
        education = row.get('Edu', 'Unknown')
        mmse = row.get('MMSE', 'Unknown')
        cdrsb = row.get('CDRSB', 'Unknown')
        
        # æ„å»ºä¸´åºŠæ–‡æœ¬æ¨¡æ¿
        clinical_text = f"""Age: {age} years
Sex: {gender}
Education: {education} years
Neuropsychological Scores:
Mini-Mental State Examination (MMSE): {mmse}/30
Clinical Dementia Rating - Sum of Boxes (CDR-SB): {cdrsb}
Diagnosis: {diagnosis}"""
        
        return clinical_text
    
    try:
        # åŠ è½½ADæ‚£è€…æ•°æ®
        print(f"ğŸ“Š åŠ è½½ADæ‚£è€…æ•°æ®: {ad_file}")
        ad_df = pd.read_excel(ad_file)
        print(f"   âœ… ADæ•°æ®å½¢çŠ¶: {ad_df.shape} (é¢„æœŸ: 414è¡Œ)")
        print(f"   ğŸ“‹ ADæ•°æ®åˆ—: {list(ad_df.columns)}")
        
        # åŠ è½½CNå¯¹ç…§ç»„æ•°æ®
        print(f"ğŸ“Š åŠ è½½CNå¯¹ç…§ç»„æ•°æ®: {cn_file}")
        cn_df = pd.read_excel(cn_file)
        print(f"   âœ… CNæ•°æ®å½¢çŠ¶: {cn_df.shape} (é¢„æœŸ: 414è¡Œ)")
        print(f"   ğŸ“‹ CNæ•°æ®åˆ—: {list(cn_df.columns)}")
        
        # éªŒè¯æ•°æ®è§„æ¨¡
        if ad_df.shape[0] != 414:
            print(f"âš ï¸  ADæ•°æ®è¡Œæ•°å¼‚å¸¸: å®é™…{ad_df.shape[0]}è¡Œ, é¢„æœŸ414è¡Œ")
        if cn_df.shape[0] != 414:
            print(f"âš ï¸  CNæ•°æ®è¡Œæ•°å¼‚å¸¸: å®é™…{cn_df.shape[0]}è¡Œ, é¢„æœŸ414è¡Œ")
        
        # éªŒè¯å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['NAME', 'Gender', 'Age', 'Edu', 'MMSE', 'CDRSB']
        
        # æ£€æŸ¥ADæ•°æ®åˆ—
        missing_ad_cols = [col for col in required_columns if col not in ad_df.columns]
        if missing_ad_cols:
            print(f"âš ï¸  ADæ•°æ®ç¼ºå°‘åˆ—: {missing_ad_cols}")
        
        # æ£€æŸ¥CNæ•°æ®åˆ—ï¼ˆå¿½ç•¥wholecodeåˆ—ï¼‰
        missing_cn_cols = [col for col in required_columns if col not in cn_df.columns]
        if missing_cn_cols:
            print(f"âš ï¸  CNæ•°æ®ç¼ºå°‘åˆ—: {missing_cn_cols}")
        
        print(f"ğŸ” ä½¿ç”¨ä¸´åºŠæ–‡æœ¬æ¨¡æ¿æ„å»ºç‰¹å¾...")
        
        # å¤„ç†ADæ•°æ® (414ä¸ªæ ·æœ¬)
        ad_count = 0
        for idx, row in ad_df.iterrows():
            try:
                # æ„å»ºä¸´åºŠæ–‡æœ¬
                clinical_text = create_clinical_text(row, "Alzheimer's Disease (AD)")
                
                # æ¸…ç†æ–‡æœ¬
                clinical_text = clean_text(clinical_text)
                if len(clinical_text.strip()) > 0:  # ç¡®ä¿ä¸æ˜¯ç©ºæ–‡æœ¬
                    texts.append(clinical_text)
                    labels.append(1)  # ADæ ‡ç­¾
                    ad_count += 1
                    
            except Exception as e:
                print(f"âš ï¸  å¤„ç†ADæ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                continue
        
        # å¤„ç†CNæ•°æ® (414ä¸ªæ ·æœ¬)
        cn_count = 0
        for idx, row in cn_df.iterrows():
            try:
                # æ„å»ºä¸´åºŠæ–‡æœ¬
                clinical_text = create_clinical_text(row, "Cognitively Normal (CN)")
                
                # æ¸…ç†æ–‡æœ¬
                clinical_text = clean_text(clinical_text)
                if len(clinical_text.strip()) > 0:  # ç¡®ä¿ä¸æ˜¯ç©ºæ–‡æœ¬
                    texts.append(clinical_text)
                    labels.append(0)  # CNæ ‡ç­¾
                    cn_count += 1
                    
            except Exception as e:
                print(f"âš ï¸  å¤„ç†CNæ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"âœ… æ–‡æœ¬æ•°æ®åŠ è½½å®Œæˆ:")
        print(f"   ğŸ“Š æ€»æ ·æœ¬æ•°: {len(texts)} (é¢„æœŸ: 828)")
        print(f"   ğŸ”¥ ADæ ·æœ¬: {ad_count} (é¢„æœŸ: 414)")
        print(f"   ğŸ”µ CNæ ·æœ¬: {cn_count} (é¢„æœŸ: 414)")
        print(f"   ğŸ“ å¹³å‡æ–‡æœ¬é•¿åº¦: {sum(len(text.split()) for text in texts) / len(texts):.1f} è¯")
        
        # æ˜¾ç¤ºæ–‡æœ¬æ ·ä¾‹
        if len(texts) > 0:
            print(f"\nğŸ“‹ æ–‡æœ¬æ ·ä¾‹ (ADæ‚£è€…):")
            ad_sample = next((text for i, text in enumerate(texts) if labels[i] == 1), None)
            if ad_sample:
                print(f"   {ad_sample[:200]}...")
            
            print(f"\nğŸ“‹ æ–‡æœ¬æ ·ä¾‹ (CNå¯¹ç…§):")
            cn_sample = next((text for i, text in enumerate(texts) if labels[i] == 0), None)
            if cn_sample:
                print(f"   {cn_sample[:200]}...")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        if len(texts) < 800:
            print(f"âš ï¸  æ–‡æœ¬æ ·æœ¬æ•°é‡åå°‘: {len(texts)}/828")
        if abs(ad_count - cn_count) > 50:
            print(f"âš ï¸  ç±»åˆ«ä¸å¹³è¡¡: AD={ad_count}, CN={cn_count}")
        
        return texts, labels
        
    except Exception as e:
        print(f"âŒ Excelæ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        print(f"ğŸ’¡ è¯·æ£€æŸ¥Excelæ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
        raise


def clean_text(text: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬æ•°æ®
    
    Args:
        text: åŸå§‹æ–‡æœ¬
    
    Returns:
        æ¸…ç†åçš„æ–‡æœ¬
    """
    if not isinstance(text, str):
        text = str(text)
    
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™åŸºæœ¬æ ‡ç‚¹ï¼‰
    text = re.sub(r'[^\w\s\.\,\!\?\-]', '', text)
    
    # è½¬æ¢ä¸ºå°å†™
    text = text.lower().strip()
    
    return text


def create_multimodal_dataset_from_excel(image_data_dir: str, 
                                        text_data_dir: str = "./æ–‡æœ¬ç¼–ç å™¨",
                                        max_samples: int = None) -> Tuple:
    """
    ä»Excelæ–‡ä»¶åˆ›å»ºå¤šæ¨¡æ€æ•°æ®é›†
    
    Args:
        image_data_dir: å›¾åƒæ•°æ®ç›®å½•
        text_data_dir: æ–‡æœ¬æ•°æ®ç›®å½•
        max_samples: æœ€å¤§æ ·æœ¬æ•°é™åˆ¶
    
    Returns:
        (image_data, texts, labels)
    """
    print("ğŸ”„ åˆ›å»ºå¤šæ¨¡æ€æ•°æ®é›†ï¼ˆä»Excelæ–‡ä»¶ï¼‰...")
    
    # åŠ è½½å›¾åƒæ•°æ®
    print("ğŸ“¸ åŠ è½½å›¾åƒæ•°æ®...")
    image_data, image_labels = load_early_fusion_data(image_data_dir, max_samples=max_samples)
    
    # åŠ è½½æ–‡æœ¬æ•°æ®
    print("ğŸ“ åŠ è½½æ–‡æœ¬æ•°æ®...")
    texts, text_labels = load_text_data_from_excel(text_data_dir)
    
    # æ•°æ®å¯¹é½æ£€æŸ¥
    print("ğŸ” æ•°æ®å¯¹é½æ£€æŸ¥...")
    print(f"   å›¾åƒæ•°æ®: {len(image_data)} æ ·æœ¬ (AD={sum(image_labels)}, CN={len(image_labels)-sum(image_labels)})")
    print(f"   æ–‡æœ¬æ•°æ®: {len(texts)} æ ·æœ¬ (AD={sum(text_labels)}, CN={len(text_labels)-sum(text_labels)})")
    
    # å¦‚æœæ•°æ®é‡ä¸åŒ¹é…ï¼Œéœ€è¦è¿›è¡Œå¯¹é½
    if len(image_data) != len(texts):
        print("âš ï¸  å›¾åƒå’Œæ–‡æœ¬æ•°æ®æ•°é‡ä¸åŒ¹é…ï¼Œè¿›è¡Œæ•°æ®å¯¹é½...")
        
        # å–è¾ƒå°çš„æ•°æ®é›†å¤§å°
        min_samples = min(len(image_data), len(texts))
        
        # æŒ‰ç±»åˆ«å¹³è¡¡é‡‡æ ·
        ad_image_indices = [i for i, label in enumerate(image_labels) if label == 1]
        cn_image_indices = [i for i, label in enumerate(image_labels) if label == 0]
        
        ad_text_indices = [i for i, label in enumerate(text_labels) if label == 1]
        cn_text_indices = [i for i, label in enumerate(text_labels) if label == 0]
        
        # è®¡ç®—æ¯ç±»çš„æ ·æœ¬æ•°
        samples_per_class = min_samples // 2
        
        # éšæœºé‡‡æ ·
        import random
        random.seed(42)
        
        selected_ad_image = random.sample(ad_image_indices, min(samples_per_class, len(ad_image_indices)))
        selected_cn_image = random.sample(cn_image_indices, min(samples_per_class, len(cn_image_indices)))
        
        selected_ad_text = random.sample(ad_text_indices, min(samples_per_class, len(ad_text_indices)))
        selected_cn_text = random.sample(cn_text_indices, min(samples_per_class, len(cn_text_indices)))
        
        # é‡æ–°ç»„ç»‡æ•°æ®
        aligned_image_data = []
        aligned_texts = []
        aligned_labels = []
        
        # ADæ ·æœ¬
        for i, (img_idx, text_idx) in enumerate(zip(selected_ad_image, selected_ad_text)):
            aligned_image_data.append(image_data[img_idx])
            aligned_texts.append(texts[text_idx])
            aligned_labels.append(1)
        
        # CNæ ·æœ¬
        for i, (img_idx, text_idx) in enumerate(zip(selected_cn_image, selected_cn_text)):
            aligned_image_data.append(image_data[img_idx])
            aligned_texts.append(texts[text_idx])
            aligned_labels.append(0)
        
        image_data = np.array(aligned_image_data)
        texts = aligned_texts
        labels = aligned_labels
        
        print(f"âœ… æ•°æ®å¯¹é½å®Œæˆ: {len(image_data)} æ ·æœ¬")
    else:
        labels = image_labels  # å‡è®¾æ ‡ç­¾ä¸€è‡´
    
    print(f"ğŸ“Š æœ€ç»ˆæ•°æ®é›†:")
    print(f"   æ ·æœ¬æ•°: {len(image_data)}")
    print(f"   å›¾åƒå½¢çŠ¶: {image_data.shape}")
    print(f"   æ–‡æœ¬æ•°: {len(texts)}")
    print(f"   æ ‡ç­¾åˆ†å¸ƒ: AD={sum(labels)}, CN={len(labels)-sum(labels)}")
    
    return image_data, texts, labels 

def load_image_data_from_nii(data_dir: str, max_samples_per_class: int = None):
    """
    ä»NIIæ–‡ä»¶åŠ è½½å›¾åƒæ•°æ®ï¼Œè¿”å›å›¾åƒæ•°æ®ã€æ ‡ç­¾å’Œæ‚£è€…ID
    
    Args:
        data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼Œåº”åŒ…å«123-AD-MRIå’Œ123-CN-MRIå­ç›®å½•
        max_samples_per_class: æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ ·æœ¬æ•°é‡é™åˆ¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        tuple: (image_data, labels, patient_ids)
            - image_data: numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸º[N, 3, D, H, W]
            - labels: numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸º[N]ï¼Œ0=CNï¼Œ1=AD
            - patient_ids: æ‚£è€…IDåˆ—è¡¨
    """
    import nibabel as nib
    from scipy.ndimage import zoom
    
    print(f"ğŸ”„ å¼€å§‹åŠ è½½å›¾åƒæ•°æ®ä»: {data_dir}")
    
    # æ„å»ºæ•°æ®è·¯å¾„ - éµå¾ªMCI_DATAè§„èŒƒ
    ad_csf_dir = os.path.join(data_dir, "totalAD", "ADfinalCSF")
    ad_gray_dir = os.path.join(data_dir, "totalAD", "ADfinalGRAY")
    ad_white_dir = os.path.join(data_dir, "totalAD", "ADfinalWHITE")
    
    cn_csf_dir = os.path.join(data_dir, "totalCN", "CNfinalCSF")
    cn_gray_dir = os.path.join(data_dir, "totalCN", "CNfinalGRAY")
    cn_white_dir = os.path.join(data_dir, "totalCN", "CNfinalWHITE")
    
    # éªŒè¯è·¯å¾„å­˜åœ¨
    required_dirs = [ad_csf_dir, ad_gray_dir, ad_white_dir, cn_csf_dir, cn_gray_dir, cn_white_dir]
    for dir_path in required_dirs:
        if not os.path.exists(dir_path):
            raise FileNotFoundError(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {dir_path}")
    
    print("âœ… æ‰€æœ‰è·¯å¾„éªŒè¯é€šè¿‡")
    
    def extract_patient_id_from_filename(filename):
        """ä»å›¾åƒæ–‡ä»¶åæå–æ‚£è€…ID"""
        basename = filename.split('.')[0]
        parts = basename.split('_')
        
        if len(parts) >= 4 and parts[0].startswith('mwp') and parts[2] == 'S':
            return f"{parts[1]}_{parts[2]}_{parts[3]}"
        
        for i in range(len(parts) - 2):
            if parts[i+1] == 'S' and parts[i].isdigit() and parts[i+2].isdigit():
                return f"{parts[i]}_{parts[i+1]}_{parts[i+2]}"
        
        return basename
    
    def load_nii_files_with_patient_id(directory):
        """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰.niiæ–‡ä»¶ï¼Œå¹¶æŒ‰æ‚£è€…IDæ’åº"""
        files = [f for f in os.listdir(directory) if f.endswith('.nii')]
        
        # æŒ‰æ‚£è€…IDæ’åºè€Œä¸æ˜¯æ–‡ä»¶åæ’åº
        file_patient_pairs = []
        for file in files:
            patient_id = extract_patient_id_from_filename(file)
            file_patient_pairs.append((file, patient_id))
        
        # æŒ‰æ‚£è€…IDæ’åº
        file_patient_pairs.sort(key=lambda x: x[1])
        sorted_files = [pair[0] for pair in file_patient_pairs]
        sorted_patient_ids = [pair[1] for pair in file_patient_pairs]
        
        data_list = []
        for file in sorted_files:
            file_path = os.path.join(directory, file)
            try:
                nii_img = nib.load(file_path)
                data = nii_img.get_fdata()
                
                # æ ‡å‡†åŒ–æ•°æ®
                if data.std() > 0:
                    data = (data - data.mean()) / data.std()
                
                # ç¡®ä¿æ•°æ®å½¢çŠ¶ä¸º[113, 137, 113]
                target_shape = (113, 137, 113)
                if data.shape != target_shape:
                    # è®¡ç®—ç¼©æ”¾å› å­
                    zoom_factors = [t/s for t, s in zip(target_shape, data.shape)]
                    data = zoom(data, zoom_factors, order=1)
                
                data_list.append(data.astype(np.float32))
                
            except Exception as e:
                print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {file}: {e}")
                continue
        
        return data_list, sorted_patient_ids
    
    # åŠ è½½ADæ•°æ® - æŒ‰æ‚£è€…IDæ’åº
    print("ğŸ“Š åŠ è½½ADæ•°æ®...")
    ad_csf_data, ad_patient_ids_csf = load_nii_files_with_patient_id(ad_csf_dir)
    ad_gray_data, ad_patient_ids_gray = load_nii_files_with_patient_id(ad_gray_dir)
    ad_white_data, ad_patient_ids_white = load_nii_files_with_patient_id(ad_white_dir)
    
    print(f"   AD CSF: {len(ad_csf_data)} æ–‡ä»¶")
    print(f"   AD GRAY: {len(ad_gray_data)} æ–‡ä»¶")
    print(f"   AD WHITE: {len(ad_white_data)} æ–‡ä»¶")
    
    # éªŒè¯ADæ•°æ®çš„æ‚£è€…IDä¸€è‡´æ€§
    if not (ad_patient_ids_csf == ad_patient_ids_gray == ad_patient_ids_white):
        print("âš ï¸  è­¦å‘Š: ADæ•°æ®ä¸­ä¸åŒç»„ç»‡ç±»å‹çš„æ‚£è€…IDé¡ºåºä¸ä¸€è‡´")
        # å–äº¤é›†ç¡®ä¿ä¸€è‡´æ€§
        common_ad_ids = list(set(ad_patient_ids_csf) & set(ad_patient_ids_gray) & set(ad_patient_ids_white))
        common_ad_ids.sort()
        print(f"   ä½¿ç”¨å…±åŒæ‚£è€…ID: {len(common_ad_ids)} ä¸ª")
    else:
        common_ad_ids = ad_patient_ids_csf
    
    # åŠ è½½CNæ•°æ® - æŒ‰æ‚£è€…IDæ’åº
    print("ğŸ“Š åŠ è½½CNæ•°æ®...")
    cn_csf_data, cn_patient_ids_csf = load_nii_files_with_patient_id(cn_csf_dir)
    cn_gray_data, cn_patient_ids_gray = load_nii_files_with_patient_id(cn_gray_dir)
    cn_white_data, cn_patient_ids_white = load_nii_files_with_patient_id(cn_white_dir)
    
    print(f"   CN CSF: {len(cn_csf_data)} æ–‡ä»¶")
    print(f"   CN GRAY: {len(cn_gray_data)} æ–‡ä»¶")
    print(f"   CN WHITE: {len(cn_white_data)} æ–‡ä»¶")
    
    # éªŒè¯CNæ•°æ®çš„æ‚£è€…IDä¸€è‡´æ€§
    if not (cn_patient_ids_csf == cn_patient_ids_gray == cn_patient_ids_white):
        print("âš ï¸  è­¦å‘Š: CNæ•°æ®ä¸­ä¸åŒç»„ç»‡ç±»å‹çš„æ‚£è€…IDé¡ºåºä¸ä¸€è‡´")
        # å–äº¤é›†ç¡®ä¿ä¸€è‡´æ€§
        common_cn_ids = list(set(cn_patient_ids_csf) & set(cn_patient_ids_gray) & set(cn_patient_ids_white))
        common_cn_ids.sort()
        print(f"   ä½¿ç”¨å…±åŒæ‚£è€…ID: {len(common_cn_ids)} ä¸ª")
    else:
        common_cn_ids = cn_patient_ids_csf
    
    # ç¡®å®šæœ€ç»ˆæ ·æœ¬æ•°é‡
    ad_count = len(common_ad_ids)
    cn_count = len(common_cn_ids)
    
    print(f"ğŸ“ˆ æ¯ç±»æœ‰æ•ˆæ ·æœ¬æ•°: AD={ad_count}, CN={cn_count}")
    
    # åº”ç”¨æ ·æœ¬æ•°é‡é™åˆ¶
    if max_samples_per_class:
        ad_count = min(ad_count, max_samples_per_class)
        cn_count = min(cn_count, max_samples_per_class)
        print(f"ğŸ”§ åº”ç”¨æ ·æœ¬é™åˆ¶: AD={ad_count}, CN={cn_count}")
    
    # æ„å»ºæ—©æœŸèåˆæ•°æ® - ç¡®ä¿æ‚£è€…IDå¯¹é½
    all_images = []
    all_labels = []
    all_patient_ids = []
    
    # å¤„ç†ADæ•°æ® - æŒ‰æ‚£è€…IDé¡ºåº
    print(f"ğŸ”„ æ„å»ºADæ•°æ®...")
    for i in range(ad_count):
        patient_id = common_ad_ids[i]
        
        # æ‰¾åˆ°å¯¹åº”çš„æ•°æ®ç´¢å¼•
        csf_idx = ad_patient_ids_csf.index(patient_id)
        gray_idx = ad_patient_ids_gray.index(patient_id)
        white_idx = ad_patient_ids_white.index(patient_id)
        
        # åˆå¹¶ä¸‰ç§ç»„ç»‡ç±»å‹ä¸º3é€šé“å›¾åƒ [CSF, GRAY, WHITE]
        combined_image = np.stack([
            ad_csf_data[csf_idx],    # é€šé“0: CSF
            ad_gray_data[gray_idx],   # é€šé“1: GRAY  
            ad_white_data[white_idx]  # é€šé“2: WHITE
        ], axis=0)  # ç»“æœå½¢çŠ¶: [3, 113, 137, 113]
        
        all_images.append(combined_image)
        all_labels.append(1)  # AD = 1
        all_patient_ids.append(patient_id)
    
    # å¤„ç†CNæ•°æ® - æŒ‰æ‚£è€…IDé¡ºåº
    print(f"ğŸ”„ æ„å»ºCNæ•°æ®...")
    for i in range(cn_count):
        patient_id = common_cn_ids[i]
        
        # æ‰¾åˆ°å¯¹åº”çš„æ•°æ®ç´¢å¼•
        csf_idx = cn_patient_ids_csf.index(patient_id)
        gray_idx = cn_patient_ids_gray.index(patient_id)
        white_idx = cn_patient_ids_white.index(patient_id)
        
        # åˆå¹¶ä¸‰ç§ç»„ç»‡ç±»å‹ä¸º3é€šé“å›¾åƒ [CSF, GRAY, WHITE]
        combined_image = np.stack([
            cn_csf_data[csf_idx],    # é€šé“0: CSF
            cn_gray_data[gray_idx],   # é€šé“1: GRAY
            cn_white_data[white_idx]  # é€šé“2: WHITE
        ], axis=0)  # ç»“æœå½¢çŠ¶: [3, 113, 137, 113]
        
        all_images.append(combined_image)
        all_labels.append(0)  # CN = 0
        all_patient_ids.append(patient_id)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    image_data = np.array(all_images, dtype=np.float32)  # [N, 3, 113, 137, 113]
    labels = np.array(all_labels, dtype=np.int64)        # [N]
    
    print(f"âœ… å›¾åƒæ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   å›¾åƒæ•°æ®å½¢çŠ¶: {image_data.shape}")
    print(f"   æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
    print(f"   æ ‡ç­¾åˆ†å¸ƒ: AD={np.sum(labels==1)}, CN={np.sum(labels==0)}")
    print(f"   æ‚£è€…IDç¤ºä¾‹: {all_patient_ids[:5]}")
    
    return image_data, labels, all_patient_ids 