#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ·±åº¦æ¶æ„å¾®è°ƒ - æ›´æ·±å±‚æ¬¡çš„ä¿¡æ¯ä¿ç•™ä¼˜åŒ–
é€šè¿‡æ¶æ„æ”¹è¿›å’Œæ¸è¿›å¼è®­ç»ƒæ¥ä¿ç•™æ›´å¤šä¿¡æ¯å¹¶æå‡æ€§èƒ½
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import CosineAnnealingLR
from tqdm import tqdm
import os
import torch.nn.functional as F

class DeepProgressiveResNetCBAM3D(nn.Module):
    """
    æ·±å±‚æ¸è¿›å¼ResNetCBAM3D - æ·±åº¦ç‰¹å¾æå–ä¼˜åŒ–
    ç‰¹ç‚¹ï¼š
    1. æ·±åº¦å¯åˆ†ç¦»å·ç§¯
    2. æ¸è¿›å¼ç‰¹å¾èšåˆ
    3. è·¨å±‚ç‰¹å¾èåˆ
    4. è‡ªé€‚åº”æ„Ÿå—é‡è°ƒæ•´
    """
    
    def __init__(self, in_channels=3, num_classes=2, base_channels=12, dropout_rate=0.3):
        super(DeepProgressiveResNetCBAM3D, self).__init__()
        
        self.base_channels = base_channels
        
        # æ·±å±‚è¾“å…¥å¤„ç† - æ¸è¿›å¼ç‰¹å¾æå–
        self.progressive_conv_blocks = nn.ModuleList([
            # ç¬¬ä¸€å±‚ï¼šç»†èŠ‚ç‰¹å¾æå–
            DepthwiseSeparableConv3D(in_channels, base_channels, kernel_size=3),
            # ç¬¬äºŒå±‚ï¼šä¸­å±‚ç‰¹å¾èšåˆ  
            DepthwiseSeparableConv3D(base_channels, base_channels, kernel_size=5),
            # ç¬¬ä¸‰å±‚ï¼šæ·±å±‚è¯­ä¹‰ç‰¹å¾
            DepthwiseSeparableConv3D(base_channels, base_channels, kernel_size=7),
        ])
        
        # è·¨å±‚ç‰¹å¾èåˆæ¨¡å—
        self.cross_layer_fusion = CrossLayerFusion(base_channels, base_channels)
        
        # è‡ªé€‚åº”æ„Ÿå—é‡è°ƒæ•´
        self.adaptive_receptive_field = AdaptiveReceptiveField(base_channels)
        
        # æ”¹è¿›çš„CBAMæ³¨æ„åŠ›æ¨¡å—
        self.spatial_attention = SpatialAttention3D()
        self.channel_attention = ChannelAttention3D(base_channels)
        
        # æ·±å±‚æ®‹å·®å—åºåˆ— - æ¸è¿›å¼æ·±åº¦æå–
        self.deep_residual_sequence = nn.ModuleList([
            DeepResidualBlock3D(base_channels, base_channels, dropout_rate),
            DeepResidualBlock3D(base_channels, base_channels * 2, dropout_rate, use_se=True),
            DeepResidualBlock3D(base_channels * 2, base_channels * 4, dropout_rate, use_se=True),
            DeepResidualBlock3D(base_channels * 4, base_channels * 4, dropout_rate, use_se=True),  # æ–°å¢æ·±å±‚
        ])
        
        # ç‰¹å¾é‡ç»„å’Œèšåˆ
        self.feature_aggregation = FeatureAggregation(base_channels * 4)
        
        # è‡ªé€‚åº”å…¨å±€æ± åŒ–
        self.adaptive_pool = nn.AdaptiveAvgPool3d((2, 2, 2))
        
        # æ·±å±‚åˆ†ç±»å™¨ - å±‚æ¬¡åŒ–ç‰¹å¾åˆ†æ
        feature_dim = base_channels * 4 * 2 * 2 * 2
        self.classifier = HierarchicalClassifier(feature_dim, num_classes, dropout_rate)
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        """æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                # ä½¿ç”¨Heåˆå§‹åŒ–ï¼Œé’ˆå¯¹ReLUæ¿€æ´»å‡½æ•°ä¼˜åŒ–
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm3d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                # ä½¿ç”¨Xavieråˆå§‹åŒ–
                nn.init.xavier_normal_(m.weight)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        # æ¸è¿›å¼æ·±åº¦ç‰¹å¾æå–
        progressive_features = []
        current_features = x
        
        for i, conv_block in enumerate(self.progressive_conv_blocks):
            current_features = conv_block(current_features)
            progressive_features.append(current_features)
        
        # è·¨å±‚ç‰¹å¾èåˆ
        fused_features = self.cross_layer_fusion(progressive_features)
        
        # è‡ªé€‚åº”æ„Ÿå—é‡è°ƒæ•´
        adaptive_features = self.adaptive_receptive_field(fused_features)
        
        # åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶
        attended_features = self.channel_attention(adaptive_features)
        attended_features = self.spatial_attention(attended_features)
        
        # æ·±å±‚æ®‹å·®åºåˆ—å¤„ç†
        deep_features = attended_features
        residual_outputs = []
        
        for deep_block in self.deep_residual_sequence:
            deep_features = deep_block(deep_features)
            residual_outputs.append(deep_features)
        
        # ç‰¹å¾èšåˆ
        aggregated_features = self.feature_aggregation(residual_outputs[-1])
        
        # å…¨å±€æ± åŒ–
        pooled_features = self.adaptive_pool(aggregated_features)
        
        # æ‰å¹³åŒ–å¹¶åˆ†ç±»
        flattened = pooled_features.view(pooled_features.size(0), -1)
        output = self.classifier(flattened)
        
        return output


class DepthwiseSeparableConv3D(nn.Module):
    """æ·±åº¦å¯åˆ†ç¦»3Då·ç§¯ - å‡å°‘å‚æ•°åŒæ—¶ä¿æŒè¡¨è¾¾èƒ½åŠ›"""
    
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None):
        super(DepthwiseSeparableConv3D, self).__init__()
        
        if padding is None:
            padding = kernel_size // 2
        
        # æ·±åº¦å·ç§¯ï¼šæ¯ä¸ªè¾“å…¥é€šé“å•ç‹¬å·ç§¯
        self.depthwise = nn.Conv3d(
            in_channels, in_channels, 
            kernel_size=kernel_size, 
            stride=stride, 
            padding=padding, 
            groups=in_channels
        )
        
        # ç‚¹å·ç§¯ï¼š1x1x1å·ç§¯ç»„åˆç‰¹å¾
        self.pointwise = nn.Conv3d(in_channels, out_channels, kernel_size=1)
        
        self.bn1 = nn.BatchNorm3d(in_channels)
        self.bn2 = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        x = self.depthwise(x)
        x = self.bn1(x)
        x = self.relu(x)
        
        x = self.pointwise(x)
        x = self.bn2(x)
        x = self.relu(x)
        
        return x


class CrossLayerFusion(nn.Module):
    """è·¨å±‚ç‰¹å¾èåˆ - èåˆä¸åŒæ·±åº¦çš„ç‰¹å¾"""
    
    def __init__(self, channels, out_channels):
        super(CrossLayerFusion, self).__init__()
        
        # ç‰¹å¾æƒé‡å­¦ä¹ 
        self.weight_conv = nn.Conv3d(channels * 3, 3, kernel_size=1)
        self.softmax = nn.Softmax(dim=1)
        
        # ç‰¹å¾èåˆ
        self.fusion_conv = nn.Conv3d(channels, out_channels, kernel_size=1)
        self.bn = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, feature_list):
        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾å…·æœ‰ç›¸åŒçš„ç©ºé—´å°ºå¯¸
        base_size = feature_list[0].shape[2:]
        aligned_features = []
        
        for feat in feature_list:
            if feat.shape[2:] != base_size:
                feat = F.interpolate(feat, size=base_size, mode='trilinear', align_corners=False)
            aligned_features.append(feat)
        
        # è®¡ç®—ç‰¹å¾æƒé‡
        concat_features = torch.cat(aligned_features, dim=1)
        weights = self.weight_conv(concat_features)
        weights = self.softmax(weights)
        
        # åŠ æƒèåˆ
        fused = sum(w * f for w, f in zip(weights.split(1, dim=1), aligned_features))
        
        # è¾“å‡ºå¤„ç†
        output = self.fusion_conv(fused)
        output = self.bn(output)
        output = self.relu(output)
        
        return output


class AdaptiveReceptiveField(nn.Module):
    """è‡ªé€‚åº”æ„Ÿå—é‡è°ƒæ•´ - åŠ¨æ€è°ƒæ•´æ„Ÿå—é‡å¤§å°"""
    
    def __init__(self, channels):
        super(AdaptiveReceptiveField, self).__init__()
        
        # å¤šç§æ„Ÿå—é‡çš„å·ç§¯
        self.conv_3x3 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)
        self.conv_5x5 = nn.Conv3d(channels, channels, kernel_size=5, padding=2)
        self.conv_7x7 = nn.Conv3d(channels, channels, kernel_size=7, padding=3)
        
        # æ„Ÿå—é‡é€‰æ‹©ç½‘ç»œ
        self.selection_net = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),
            nn.Conv3d(channels, channels // 4, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels // 4, 3, kernel_size=1),
            nn.Softmax(dim=1)
        )
        
        self.bn = nn.BatchNorm3d(channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        # è®¡ç®—ä¸åŒæ„Ÿå—é‡çš„ç‰¹å¾
        feat_3x3 = self.conv_3x3(x)
        feat_5x5 = self.conv_5x5(x)
        feat_7x7 = self.conv_7x7(x)
        
        # è‡ªé€‚åº”é€‰æ‹©æƒé‡
        selection_weights = self.selection_net(x)
        w1, w2, w3 = selection_weights[:, 0:1], selection_weights[:, 1:2], selection_weights[:, 2:3]
        
        # åŠ æƒèåˆ
        adaptive_feat = w1 * feat_3x3 + w2 * feat_5x5 + w3 * feat_7x7
        
        # æ®‹å·®è¿æ¥
        output = adaptive_feat + x
        output = self.bn(output)
        output = self.relu(output)
        
        return output


class DeepResidualBlock3D(nn.Module):
    """æ·±å±‚æ®‹å·®å— - å¢å¼ºç‰ˆæ®‹å·®å­¦ä¹ """
    
    def __init__(self, in_channels, out_channels, dropout_rate=0.3, use_se=False):
        super(DeepResidualBlock3D, self).__init__()
        
        # ä¸»åˆ†æ”¯
        self.conv1 = nn.Conv3d(in_channels, out_channels // 2, kernel_size=1)
        self.bn1 = nn.BatchNorm3d(out_channels // 2)
        
        self.conv2 = nn.Conv3d(out_channels // 2, out_channels // 2, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm3d(out_channels // 2)
        
        self.conv3 = nn.Conv3d(out_channels // 2, out_channels, kernel_size=1)
        self.bn3 = nn.BatchNorm3d(out_channels)
        
        # SEæ¨¡å—ï¼ˆå¯é€‰ï¼‰
        self.use_se = use_se
        if use_se:
            self.se_module = SEModule3D(out_channels)
        
        # æ®‹å·®è¿æ¥
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv3d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm3d(out_channels)
            )
        
        self.dropout = nn.Dropout3d(dropout_rate)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        residual = self.shortcut(x)
        
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.dropout(out)
        
        out = self.relu(self.bn2(self.conv2(out)))
        out = self.dropout(out)
        
        out = self.bn3(self.conv3(out))
        
        if self.use_se:
            out = self.se_module(out)
        
        out += residual
        out = self.relu(out)
        
        return out


class SEModule3D(nn.Module):
    """3D Squeeze-and-Excitationæ¨¡å—"""
    
    def __init__(self, channels, reduction=16):
        super(SEModule3D, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1, 1)
        return x * y.expand_as(x)


class FeatureAggregation(nn.Module):
    """ç‰¹å¾èšåˆæ¨¡å— - æ•´åˆæ·±å±‚ç‰¹å¾"""
    
    def __init__(self, channels):
        super(FeatureAggregation, self).__init__()
        
        # å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡
        self.global_context = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),
            nn.Conv3d(channels, channels // 2, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels // 2, channels, kernel_size=1),
            nn.Sigmoid()
        )
        
        # å±€éƒ¨ç»†èŠ‚å¢å¼º
        self.local_enhance = nn.Conv3d(channels, channels, kernel_size=3, padding=1)
        self.bn = nn.BatchNorm3d(channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        # å…¨å±€ä¸Šä¸‹æ–‡æƒé‡
        global_weight = self.global_context(x)
        
        # å±€éƒ¨ç‰¹å¾å¢å¼º
        local_feat = self.local_enhance(x)
        
        # èåˆå…¨å±€å’Œå±€éƒ¨ä¿¡æ¯
        enhanced = x * global_weight + local_feat
        enhanced = self.bn(enhanced)
        enhanced = self.relu(enhanced)
        
        return enhanced


class HierarchicalClassifier(nn.Module):
    """å±‚æ¬¡åŒ–åˆ†ç±»å™¨ - æ¸è¿›å¼å†³ç­–"""
    
    def __init__(self, input_dim, num_classes, dropout_rate=0.3):
        super(HierarchicalClassifier, self).__init__()
        
        # å¤šå±‚æ¸è¿›å¼åˆ†ç±»
        self.layer1 = nn.Sequential(
            nn.Linear(input_dim, input_dim // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate)
        )
        
        self.layer2 = nn.Sequential(
            nn.Linear(input_dim // 2, input_dim // 4),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate)
        )
        
        self.layer3 = nn.Sequential(
            nn.Linear(input_dim // 4, input_dim // 8),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate // 2)  # æœ€åå±‚é™ä½dropout
        )
        
        self.final_classifier = nn.Linear(input_dim // 8, num_classes)
        
        # è¾…åŠ©åˆ†ç±»å™¨ï¼ˆå¯é€‰ï¼Œç”¨äºæ·±åº¦ç›‘ç£ï¼‰
        self.aux_classifier = nn.Linear(input_dim // 4, num_classes)
    
    def forward(self, x):
        x1 = self.layer1(x)
        x2 = self.layer2(x1)
        x3 = self.layer3(x2)
        
        # ä¸»è¦è¾“å‡º
        main_output = self.final_classifier(x3)
        
        # è®­ç»ƒæ—¶å¯ä»¥æ·»åŠ è¾…åŠ©æŸå¤±
        if self.training:
            aux_output = self.aux_classifier(x2)
            return main_output, aux_output
        else:
            return main_output


class ChannelAttention3D(nn.Module):
    """3Dé€šé“æ³¨æ„åŠ›æ¨¡å—"""
    
    def __init__(self, channels, reduction=16):
        super(ChannelAttention3D, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.max_pool = nn.AdaptiveMaxPool3d(1)
        
        self.fc = nn.Sequential(
            nn.Conv3d(channels, channels // reduction, kernel_size=1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels // reduction, channels, kernel_size=1, bias=False)
        )
        
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        attention = self.sigmoid(avg_out + max_out)
        return x * attention


class SpatialAttention3D(nn.Module):
    """3Dç©ºé—´æ³¨æ„åŠ›æ¨¡å—"""
    
    def __init__(self, kernel_size=7):
        super(SpatialAttention3D, self).__init__()
        self.conv = nn.Conv3d(2, 1, kernel_size=kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        attention_input = torch.cat([avg_out, max_out], dim=1)
        attention = self.sigmoid(self.conv(attention_input))
        return x * attention


def deep_architecture_finetune(model_path, data_loaders, device, epochs=10):
    """
    æ·±åº¦æ¶æ„å¾®è°ƒ
    
    å‚æ•°:
    - model_path: åŸå§‹æ¨¡å‹è·¯å¾„
    - data_loaders: æ•°æ®åŠ è½½å™¨
    - device: è®¡ç®—è®¾å¤‡
    - epochs: è®­ç»ƒè½®æ¬¡
    
    è¿”å›:
    - å¾®è°ƒåçš„æ€§èƒ½
    """
    print(f"\n===== æ·±åº¦æ¶æ„å¾®è°ƒ (å¢å¼ºç‰ˆæ¨¡å‹ï¼Œ{epochs}è½®) =====")
    
    # åˆ›å»ºå¢å¼ºç‰ˆæ¨¡å‹
    enhanced_model = DeepProgressiveResNetCBAM3D(
        in_channels=3,
        num_classes=2,
        base_channels=12,
        dropout_rate=0.2  # é™ä½dropoutä»¥ä¿ç•™æ›´å¤šä¿¡æ¯
    ).to(device)
    
    print("âœ… åˆ›å»ºæ·±å±‚æ¸è¿›å¼æ¶æ„æ¨¡å‹")
    print(f"   - æ·±åº¦å¯åˆ†ç¦»å·ç§¯")
    print(f"   - æ¸è¿›å¼ç‰¹å¾èšåˆ")
    print(f"   - è·¨å±‚ç‰¹å¾èåˆ")
    print(f"   - è‡ªé€‚åº”æ„Ÿå—é‡è°ƒæ•´")
    print(f"   - SEæ¨¡å—å¢å¼º")
    print(f"   - å±‚æ¬¡åŒ–åˆ†ç±»å™¨")
    
    # æ•°æ®åŠ è½½å™¨
    from early_fusion_fixed import create_memory_optimized_early_fusion_loaders
    fusion_loaders = create_memory_optimized_early_fusion_loaders(
        data_loaders, gpu_memory_gb=32, debug=False
    )
    
    train_loader = fusion_loaders['train']
    val_loader = fusion_loaders['val']
    
    # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´ç»†è‡´çš„å­¦ä¹ ç‡
    optimizer = optim.AdamW(
        enhanced_model.parameters(),
        lr=0.0001,  # é€‚ä¸­çš„å­¦ä¹ ç‡
        weight_decay=0.01,
        eps=1e-8
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ¸©å’Œçš„ä½™å¼¦é€€ç«
    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)
    
    # æ”¹è¿›çš„æŸå¤±å‡½æ•° - æ ‡ç­¾å¹³æ»‘
    class LabelSmoothingLoss(nn.Module):
        def __init__(self, num_classes=2, smoothing=0.1):
            super(LabelSmoothingLoss, self).__init__()
            self.num_classes = num_classes
            self.smoothing = smoothing
            
        def forward(self, inputs, targets):
            log_probs = F.log_softmax(inputs, dim=1)
            targets_one_hot = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)
            targets_smooth = (1 - self.smoothing) * targets_one_hot + self.smoothing / self.num_classes
            loss = -torch.sum(targets_smooth * log_probs, dim=1).mean()
            return loss
    
    criterion = LabelSmoothingLoss(smoothing=0.1)
    
    best_val_acc = 0.0
    enhanced_model.train()
    
    print(f"\nğŸš€ å¼€å§‹æ·±åº¦æ¶æ„å¾®è°ƒè®­ç»ƒ...")
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        train_pbar = tqdm(train_loader, desc=f"æ¶æ„å¾®è°ƒ {epoch+1}/{epochs}")
        for batch_idx, (inputs, labels) in enumerate(train_pbar):
            inputs, labels = inputs.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = enhanced_model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(enhanced_model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()
            
            train_acc = 100. * train_correct / train_total
            train_pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{train_acc:.2f}%'
            })
        
        # éªŒè¯é˜¶æ®µ
        enhanced_model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        class_correct = [0, 0]
        class_total = [0, 0]
        
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = enhanced_model(inputs)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()
                
                # ç±»åˆ«å‡†ç¡®ç‡ç»Ÿè®¡
                for i in range(labels.size(0)):
                    label = labels[i].item()
                    class_total[label] += 1
                    if predicted[i] == label:
                        class_correct[label] += 1
        
        val_acc = 100. * val_correct / val_total
        ad_acc = 100. * class_correct[0] / class_total[0] if class_total[0] > 0 else 0
        cn_acc = 100. * class_correct[1] / class_total[1] if class_total[1] > 0 else 0
        
        # æ›´æ–°æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(enhanced_model.state_dict(), './models/enhanced_architecture_model.pth')
            print(f"\nâœ… ä¿å­˜å¢å¼ºæ¶æ„æ¨¡å‹ï¼ŒéªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
        
        scheduler.step()
        enhanced_model.train()
        
        print(f"\nè½®æ¬¡ [{epoch+1}/{epochs}] - æ·±åº¦æ¶æ„å¾®è°ƒ:")
        print(f"   è®­ç»ƒå‡†ç¡®ç‡: {100.*train_correct/train_total:.2f}%")
        print(f"   éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
        print(f"   ç±»åˆ«å‡†ç¡®ç‡: AD={ad_acc:.2f}%, CN={cn_acc:.2f}%")
        print(f"   å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")
    
    print(f"\nğŸ‰ æ·±åº¦æ¶æ„å¾®è°ƒå®Œæˆï¼")
    print(f"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
    print(f"ğŸ“ å¢å¼ºæ¨¡å‹ä¿å­˜: ./models/enhanced_architecture_model.pth")
    
    return best_val_acc


if __name__ == "__main__":
    print("æ·±åº¦æ¶æ„å¾®è°ƒè„šæœ¬å°±ç»ªï¼") 