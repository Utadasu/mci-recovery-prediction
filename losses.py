import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class LabelSmoothingLoss(nn.Module):
    """
    å¸¦æ ‡ç­¾å¹³æ»‘çš„äº¤å‰ç†µæŸå¤±å‡½æ•°
    è¿™èƒ½å‡å°‘æ¨¡å‹è¿‡åº¦è‡ªä¿¡ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
    """
    def __init__(self, classes=2, smoothing=0.1, dim=-1):
        super(LabelSmoothingLoss, self).__init__()
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
        self.cls = classes
        self.dim = dim

    def forward(self, pred, target):
        pred = pred.log_softmax(dim=self.dim)
        with torch.no_grad():
            # åˆ›å»ºå¹³æ»‘æ ‡ç­¾
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.cls - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))

class FocalLoss(nn.Module):
    """
    Focal Lossèƒ½å¸®åŠ©è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
    é™ä½æ˜“åˆ†æ ·æœ¬çš„æƒé‡ï¼Œå¢åŠ éš¾åˆ†æ ·æœ¬çš„æƒé‡
    """
    def __init__(self, alpha=0.25, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class ImprovedFocalLoss(nn.Module):
    """
    æ”¹è¿›çš„Focal Loss - ä¸“é—¨ä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…åˆ†ç±»ä¼˜åŒ–
    
    åŠŸèƒ½ç‰¹æ€§:
    - ğŸ¯ è‡ªé€‚åº”alphaæƒé‡ï¼Œæ ¹æ®ç±»åˆ«åˆ†å¸ƒåŠ¨æ€è°ƒæ•´
    - ğŸ”§ å¯é…ç½®gammaå‚æ•°ï¼Œæ§åˆ¶éš¾æ˜“æ ·æœ¬æƒé‡
    - ğŸ“Š æ”¯æŒç±»åˆ«æƒé‡ï¼Œå¤„ç†æ•°æ®ä¸å¹³è¡¡
    - ğŸ›¡ï¸ æ•°å€¼ç¨³å®šæ€§ä¼˜åŒ–ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸
    """
    def __init__(self, alpha=1.0, gamma=2.0, class_weights=None, reduction='mean', eps=1e-8):
        super(ImprovedFocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        self.eps = eps
        
        # ç±»åˆ«æƒé‡ - é»˜è®¤ç»™ADç±»åˆ«ç¨é«˜æƒé‡
        if class_weights is None:
            self.class_weights = torch.tensor([1.0, 1.2])  # [CN, AD]
        else:
            self.class_weights = torch.tensor(class_weights)
    
    def forward(self, inputs, targets):
        """
        å‰å‘ä¼ æ’­
        Args:
            inputs: æ¨¡å‹è¾“å‡ºlogits [B, num_classes]
            targets: çœŸå®æ ‡ç­¾ [B]
        Returns:
            loss: Focal Losså€¼
        """
        # ç¡®ä¿class_weightsåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if self.class_weights.device != inputs.device:
            self.class_weights = self.class_weights.to(inputs.device)
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤± (ä¸è¿›è¡Œreduction)
        ce_loss = F.cross_entropy(inputs, targets, weight=self.class_weights, reduction='none')
        
        # è®¡ç®—æ¦‚ç‡
        pt = torch.exp(-ce_loss + self.eps)  # æ·»åŠ epsé¿å…æ•°å€¼ä¸ç¨³å®š
        
        # è®¡ç®—alphaæƒé‡
        if isinstance(self.alpha, (float, int)):
            alpha_t = self.alpha
        else:
            # å¦‚æœalphaæ˜¯tensorï¼Œæ ¹æ®targetsé€‰æ‹©å¯¹åº”æƒé‡
            alpha_t = self.alpha[targets]
        
        # è®¡ç®—Focal Loss
        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss
        
        # åº”ç”¨reduction
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

def to_one_hot(labels, num_classes=2):
    """Convert class labels to one-hot encoding"""
    batch_size = labels.size(0)
    one_hot = torch.zeros(batch_size, num_classes, device=labels.device)
    one_hot.scatter_(1, labels.unsqueeze(1), 1)
    return one_hot

def combined_criterion(outputs, targets, smoothing=0.1, focal_weight=0.5):
    """
    ç»„åˆå¤šä¸ªæŸå¤±å‡½æ•°ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
    - äº¤å‰ç†µæŸå¤±ï¼šåŸºç¡€åˆ†ç±»æŸå¤±
    - æ ‡ç­¾å¹³æ»‘ï¼šå‡è½»è¿‡æ‹Ÿåˆ
    - Focal Lossï¼šå¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    """
    # æ ‡å‡†äº¤å‰ç†µ
    ce_loss = nn.CrossEntropyLoss()(outputs, targets)
    
    # æ ‡ç­¾å¹³æ»‘
    ls_loss = LabelSmoothingLoss(smoothing=smoothing)(outputs, targets)
    
    # Focal Loss
    focal_loss = FocalLoss()(outputs, targets)
    
    # ç»„åˆæŸå¤±
    combined_loss = ce_loss * 0.4 + ls_loss * 0.3 + focal_loss * focal_weight * 0.3
    
    return combined_loss

def weighted_criterion(outputs, targets, class_weights=None):
    """
    å¸¦ç±»åˆ«æƒé‡çš„äº¤å‰ç†µæŸå¤±
    é€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®é›†
    """
    if class_weights is None:
        # é»˜è®¤ç»™ADç±»åˆ«æ›´é«˜çš„æƒé‡(1.5)ï¼ŒCNç±»åˆ«æƒé‡ä¸º1.0
        class_weights = torch.tensor([1.5, 1.0]).to(outputs.device)
    
    return nn.CrossEntropyLoss(weight=class_weights)(outputs, targets) 